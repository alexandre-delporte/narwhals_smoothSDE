---
title: "simulation_study_spline"
author: "Alexandre Delporte"
date: "2024-12-01"
output: html_document
---

This is a simulation study dedicated to the estimation of the parameters in our CRCVM SDE model.
We try different framework to decide which one we choose for the calculations on the university clusters.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(here)
library(sf)
library(smoothSDE)
library(doParallel)
library(ggplot2)
library(dplyr)
library(mgcv)
library(plotly)

#get functions to simulate trajectories
source(file.path(here("R","simulation_study_CRCVM","CVM_functions.R")))  


```



# Simple framework : no random effects 



## Define hyperparameters 


```{r hyperparameters}
N_ID=6

TMAX=12
DELTA=1/60/6

SP_DF=c(5,5)

TAU_0=1.3
NU_0=4.6

DMIN=0.5
DMAX=1

PAR0_RACVM=c(0,0,1,1,0)

SIGMA_OBS_LOW=0.01
SIGMA_OBS_HIGH=0.04

BY_LF=5
BY_HF=1

D_LOW=0.05
D_UP=3

A=1
D0=0.3
D1=1.2
SIGMA_THETA=pi/6
SIGMA_D=1
B=1

```

```{r initial positions}

seed=42
set.seed(seed)
# Set the path to the directory containing the data
greenland_data_path <- here("Data","preprocessed_data","greenland")

#get the land geometry from shapefile
border<-st_read(file.path(greenland_data_path,"updated_scoresby_sound_utm.shp"))
border <- st_transform(border, crs = "+init=EPSG:32626 +units=km")

shrunk_border<-st_read(file.path(greenland_data_path,"shrunk_updated_scoresby_sound_utm.shp"))
shrunk_border <- st_transform(border, crs = "+init=EPSG:32626 +units=km")
v0=c(0,0)

#generate random initial points
x0=matrix(rep(NA,N_ID*2),ncol=2)
colnames(x0)=c("x1","x2")

i=1
while (i<=N_ID) {
  #choose location uniformly in the map
  x=c(runif(1,min=430,max=500),runif(1,min=7760,max=7900))
  if (!(is_in_land(st_point(x),border))) {
    p=nearest_boundary_point(st_point(x),border)
    Dshore=(x[1]-p[1])^2+(x[2]-p[2])^2
    #keep it as initial position if it is at least 50 metres away from the shore
    if (Dshore>DMIN && Dshore<DMAX) {
      x0[i,]=x
      i=i+1
    }
  }
}


```


## Define SDE parameters


```{r model parameters}
# Time steps ----------------


#high frequency time points
times=seq(0,TMAX,by=DELTA)

n_obs=length(times)-1


# Defintion of smooth parameter omega ----------

fomega_cubic=function(cov_data,a,b,D0,D1,sigma_D,sigma_theta){
  Dshore=cov_data$DistanceShore
  theta=cov_data$theta
  if (is.null(Dshore)){
    Dshore=1/cov_data$Ishore
  }
  
  a*theta*(theta-pi/2)*(theta+pi/2)*exp(-Dshore/D0)/Dshore+
      b*(exp(-1/2*(((theta+pi/2/sqrt(3))/sigma_theta)^2+((Dshore-D1)/sigma_D)^2))-
           exp(-1/2*(((theta-pi/2/sqrt(3))/sigma_theta)^2+((Dshore-D1)/sigma_D)^2)))
}


fomega=function(cov_data) {
  fomega_cubic(cov_data,A,B,D0,D1,SIGMA_D,SIGMA_THETA)
}

ftau_constant=function(cov_data) {
  TAU_0
}

fnu_constant=function(cov_data) {
  NU_0
}


```

## Simulate true trajectories

```{r,cache=TRUE}

# Generate samples ---------------

cores=detectCores()
cl <- makeCluster(6) #not to overload your computer
registerDoParallel(cl)



data=foreach (i=1:N_ID,.combine='rbind',.packages=c("progress","MASS","sf","mgcv")) %dopar% {
  
  set.seed((seed-1)*N_ID+i)

  
  res=sim_CRCVM(ftau=ftau_constant,fomega=fomega,fnu=fnu_constant,
                      log_sigma_obs=NULL,v0=v0,x0=x0[i,],times=times,
                land=shrunk_border,verbose=FALSE,save_omega = TRUE)
  
  data_sim=res$sim
  data_sim$ID=factor(rep(i,length(data_sim$y1)))
  data_shore=res$shore

  data_sim=cbind(data_sim,data_shore)
  data_sim
}

#stop cluster
stopCluster(cl)

```

## Remove trajectories that reached land

```{r}


# Points that reached land ---------------
count=0
remove_ID=c()
for (id in unique(data$ID)) {
  id_data=data[data$ID==id,]
  if (nrow(id_data) < n_obs) {
    count=count+1
    remove_ID=c(remove_ID,id)
    cat("ID",id,"reached land","\n",sep=" ")
  }
}

cat(count/N_ID*100,"percent of the trajectories reached land","\n")


data_sub=data %>%  filter(!(ID %in% remove_ID))



```

## Add noise to get observed trajectories

```{r}
# add noise
low_noise=rmvn(n_obs,rep(0,2),diag(rep(SIGMA_OBS_LOW^2,2)))
high_noise=rmvn(n_obs,rep(0,2),diag(rep(SIGMA_OBS_HIGH^2,2)))
observed_data_le=data_sub[,c("y1","y2","time","ID")]
observed_data_le[,c("y1","y2")]=data_sub[,c("y1","y2")]+low_noise
observed_data_he=data_sub[,c("y1","y2","time","ID")]
observed_data_he[,c("y1","y2")]=data_sub[,c("y1","y2")]+high_noise

#subsample
data_lf_he=observed_data_he[seq(1,length(data_sub$time),by=BY_LF),]
data_lf_le=observed_data_le[seq(1,length(data_sub$time),by=BY_LF),]
data_hf_le=observed_data_le[seq(1,length(data_sub$time),by=BY_HF),]
data_hf_he=observed_data_he[seq(1,length(data_sub$time),by=BY_HF),]


# Save plot of the trajectories ------------

plot=ggplot()+geom_sf(data=border$geometry,fill="grey")+
  coord_sf(datum=st_crs("+init=EPSG:32626 +units=km"))+
  geom_point(data=data_sub,mapping=aes(y1,y2,col=ID),size=0.1,alpha=0.2,shape=2)+
  geom_point(data=data_lf_he,mapping=aes(y1,y2,col=ID),size=0.1)+
  geom_path(data=data_lf_he,mapping=aes(y1,y2,col=ID),size=0.1)+
  geom_point(data = data%>% filter(!duplicated(ID)),
             aes(x = y1, y = y2), shape = 3, size = 4, col = "red")+
  xlab("x") + ylab("y")


ggsave(filename="plot_trajectories.pdf",plot=plot,width=10,height=5)

```

## Compute covariates from observations


```{r}


# Add covariates to data -----------

signed_angle <- function(u, v) {
  #Compute signed angle in [-pi,pi] that rotates first vector into second vector 
  # as in 
  # https://math.stackexchange.com/questions/529555/signed-angle-between-2-vectors
  u <- matrix(u, ncol = 2)
  v <- matrix(v, ncol = 2)
  if (nrow(u) != nrow(v)) stop("u and v must have the same number of 
                                  rows")
  result <- as.numeric(atan2(v[,2], v[,1]) - atan2(u[,2], u[,1]))
  ind1 <- which(result > pi)
  ind2 <- which(result <= -pi)
  result[ind1] <- result[ind1] - 2*pi
  result[ind2] <- result[ind2] + 2*pi
  return(result) 
} 

  # Function to calculate rolling average
rolling_average <- function(data, window) {
  n <- nrow(data)
  result <- matrix(NA, n, ncol(data))  # Initialize result matrix with NA
  colnames(result) <- colnames(data)

  for (i in seq_len(n)) {
    # Define the range for the current window
    start <- max(1, i - floor(window / 2))
    end <- min(n, i + floor(window / 2))
    result[i, ] <- colMeans(data[start:end, , drop = FALSE])  # Compute column means
  }
  return(result)
}


add_covs_parallel <- function(data,add="all",window=1,n_cores = parallel::detectCores() - 1) {
  # Setup parallel backend
  cl <- makeCluster(n_cores)
  registerDoParallel(cl)
  
  # Split data by ID
  ids <- unique(data$ID)
  
  # Process each ID in parallel
  results <- foreach(id = ids, .combine = rbind, .packages = c("sf"),
                     .export = c("nearest_boundary_points", "is_in_land", "signed_angle","border",
                                 "D_LOW","D_UP","rolling_average")  ) %dopar% {
    # Filter data for the current ID
    sub_data <- data[data$ID == id, ]
    n_sub <- nrow(sub_data)
    
    # Time steps
    dtimes <- sub_data[2:n_sub, "time"] - sub_data[1:(n_sub - 1), "time"]
    
    # Step lengths
    dx <- sub_data[2:n_sub, "y1"] - sub_data[1:(n_sub - 1), "y1"]
    dy <- sub_data[2:n_sub, "y2"] - sub_data[1:(n_sub - 1), "y2"]
    
    # Empirical velocity
    vexp_df <- cbind(dx / dtimes, dy / dtimes) 
    

    vexp_avg <- rolling_average(vexp_df, window)

    # Nearest points on shore
    sub_data <- cbind(sub_data, nearest_boundary_points(as.matrix(sub_data[, c("y1", "y2")]), border))
    
    # Normal vectors
    normal <- as.matrix(sub_data[2:n_sub, c("y1", "y2")] - sub_data[2:n_sub, c("p1", "p2")])
    
    # Angle between velocity and normal vector
    theta_coast <- signed_angle(normal, vexp_avg)
    theta_coast <- c(theta_coast, 1)  # Adjust length
    
    # Initialize DistanceShore
    Dshore <- rep(0, n_sub)
    
    for (i in 1:n_sub) {
      y1 <- sub_data[i, "y1"]
      y2 <- sub_data[i, "y2"]
      if (!is_in_land(st_point(c(y1, y2)), border)) {
        p1 <- sub_data[i, "p1"]
        p2 <- sub_data[i, "p2"]
        Dshore[i] <- sqrt((y1 - p1)^2 + (y2 - p2)^2)
      }
    }
    
    Dshore_avg=as.vector(rolling_average(matrix(Dshore,ncol=1),window))
    
    # Calculate Ishore
    Ishore_avg <- ifelse(Dshore_avg < D_LOW, 1 / D_LOW, ifelse(Dshore_avg > D_UP, 0, 1 / Dshore_avg))
    
    # Add columns to sub_data
    if (add=="all") {
      sub_data$theta <- theta_coast
      sub_data$DistanceShore <- Dshore_avg
      sub_data$Ishore <- Ishore_avg
    }
    else if (add=="theta") {
      sub_data$theta <- theta_coast
    }
    else if (add=="DistanceShore") {
      sub_data$DistanceShore <- Dshore
      sub_data$Ishore <- Ishore
        }
  else {
    stop("Options for argument add are \"all\",\"DistanceShore\" and \"theta\"")
  }
    
    return(sub_data)
  }
  
  # Stop the cluster
  stopCluster(cl)
  
  return(results)
}

```

```{r}
#colnames(data)[8]="DistanceShore"
data_lf_he=add_covs_parallel(data_lf_he,window=3)
data_hf_le=add_covs_parallel(data_hf_le,window=3)
data_lf_le=add_covs_parallel(data_lf_le,window=3)
data_hf_he=add_covs_parallel(data_hf_he,window=3)
```


```{r}

plot_Dshore=ggplot(data=data_lf_he)+geom_point(aes(x=time,y=DistanceShore,col=ID),size=1,alpha=0.5)+
  geom_line(aes(x=time,y=DistanceShore,col=ID),size=1,alpha=0.2)+facet_wrap(~ID)+
  theme_minimal()

plot_Dshore

```

```{r}

ggplot(data_lf_he)+geom_histogram(aes(x=DistanceShore),bins=30)+facet_wrap(~ID)+theme_minimal()
quantile(data_lf_he$DistanceShore)
```

```{r}


data_lf_he$angular_velocity=as.vector(sapply(unique(data_sub$ID),function(id){
  c(NA,diff(data_lf_he[data_lf_he$ID==id,"theta"])/diff(data_lf_he[data_lf_he$ID==id,"time"]))}))
  
  
plot_angular_velocity=ggplot(data=data_lf_he)+geom_point(aes(x=time,y=angular_velocity,col=ID),size=1,alpha=0.5)+
  geom_line(aes(x=time,y=angular_velocity,col=ID),size=1,alpha=0.2)+facet_wrap(~ID)+
  theme_minimal()
plot_angular_velocity




```


```{r}

ggplot(data_lf_he)+geom_histogram(aes(x=angular_velocity),bins=30)+facet_wrap(~ID)+theme_minimal()
quantile(data_lf_he$angular_velocity,na.rm=TRUE)

```


```{r}
data_lf_he$speed=as.vector(sapply(unique(data_sub$ID),function(id) {c(NA,sqrt(diff(data_lf_he[data_lf_he$ID==id,"y1"])^2+diff(data_lf_he[data_lf_he$ID==id,"y2"])^2)
                                                                      /diff(data_lf_he[data_lf_he$ID==id,"time"]))}))
                                  
ggplot(data_lf_he)+geom_histogram(aes(x=speed),bins=30)+facet_wrap(~ID)+theme_minimal()
quantile(data_lf_he$speed,na.rm=TRUE)
```
```{r}
ggplot(data_lf_he)+geom_histogram(aes(x=theta),bins=30)+facet_wrap(~ID)+theme_minimal()
```

## Estimate CTCRW

### low frequency high error

First we estimate $\tau$ and $\nu$ while ignoring the spatial constraints that are included in $\omega$.
We only keep 2 of the twelve trajectories.


```{r fit sde model with splines,cache=TRUE}

formulas <- list(mu1=~1,mu2=~1,tau=~1,nu=~1)

ctcrw_lf_he<- SDE$new(formulas = formulas,data =data_lf_he[data_lf_he$ID %in% c(1,2,4,5),],type = "CTCRW",
                    response = c("y1","y2"),par0 = c(0,0,1,1),fixpar=c("mu1","mu2"),
                    other_data=list("log_sigma_obs0"=log(0.05)))

#fit
ctcrw_lf_he$fit(method="BFGS")
```
```{r}
ctcrw_lf_he$get_all_plots()
exp(as.list(ctcrw_lf_he$tmb_rep(),what="Estimate")$log_sigma_obs)
```

It seems that the estimate for $\tau$ is biaised. While $\nu$ is well estimated, 
$\tau$ seems to be significantly underestimated. The reason is probably that some of the turns in the trajectories that are due to the parameter $\omega$ are attributed to a lower persistence since we do not model $\omega$ here. This is indeed in agreement with the results we get from fitting a CTCRW to the narwhal data. The trajectories from the fitted model seemed Here, if we play with the number of trajectories used for the estimation, we see that for some trajectories we are able to get both $\tau$ and $\nu$ right. The parameter $\sigma_{obs}$ for the measurement error is also well estimated.


### Low frequency low error

```{r fit sde model with splines,cache=TRUE}


formulas <- list(mu1=~1,mu2=~1,tau=~1,nu=~1,omega=~1)


ctcrw_lf_le<- SDE$new(formulas = formulas,data =data_lf_le[data_lf_le$ID %in% c(1:6),],type = "RACVM_SSM",
                    response = c("y1","y2"),par0 = c(0,0,1,1,0),fixpar=c("mu1","mu2"),
                    other_data=list("log_sigma_obs0"=log(0.03)))

#fit
ctcrw_lf_le$fit(method="BFGS")
```
```{r}
ctcrw_lf_le$get_all_plots()
exp(as.list(ctcrw_lf_le$tmb_rep(),what="Estimate")$log_sigma_obs)

```

We are still estimating $\nu$ and $\sigma_{obs}$ right, but $\tau$ is also still underestimated. Thus, reducing the measurement error does not help get a better estimate of $\tau$ here.

### High frequency low error

```{r fit sde model with splines,cache=TRUE}


formulas <- list(mu1=~1,mu2=~1,tau=~1,nu=~1)


ctcrw_hf_le<- SDE$new(formulas = formulas,data =data_hf_le,type = "CTCRW",
                    response = c("y1","y2"),par0 = c(0,0,1,1),fixpar=c("mu1","mu2"),
                    other_data=list("log_sigma_obs0"=log(0.03)))

#fit
ctcrw_hf_le$fit(method="BFGS")
```
```{r}
ctcrw_hf_le$get_all_plots()

exp(as.list(ctcrw_hf_le$tmb_rep(),what="Estimate")$log_sigma_obs)

```

The estimate is slightly less biased here, but still increasing the resolution of the data does not really help to correct the biais on $\tau$.

### High frequency high error

If we take all the data points, we get numerical errors during the estimation with a non definite positive Hessian matrix.

```{r fit sde model with splines,cache=TRUE}


formulas <- list(mu1=~1,mu2=~1,tau=~1,nu=~1)


ctcrw_hf_he<- SDE$new(formulas = formulas,data =data_hf_he[data_hf_he$ID %in% c(1,2,3),],type = "CTCRW",
                    response = c("y1","y2"),par0 = c(0,0,1,1),fixpar=c("mu1","mu2"),
                    other_data=list("log_sigma_obs0"=log(0.05)))

#fit
ctcrw_hf_he$fit(method="BFGS")
```
```{r}
ctcrw_hf_he$get_all_plots()

exp(as.list(ctcrw_hf_he$tmb_rep(),what="Estimate")$log_sigma_obs)

```

Whether we have low error or high error, we still have a biased estimate of $\tau$.
We now introduce the parameter $\omega$ in the model.


## Estimate RACVM with splines

Now we can try to add parameter $\omega$ in the model.
We are limited by the RAM of the computer that is why we would need to do this on the university clusters with longer or higher frequency trajectories.
We need to fix the smoothing penalties otherwise they are either estimated to very high or very low values meaning that numerical errors occurred.

First, we get good values for the smoothing penalty by approximating the true surface with splines.

```{r}
# Splines smooth for omega -------------------- 
n <- 100000
SP_DF=5

#sample theta and DistanceShore points in the domain
theta <- runif(n,-pi,pi);
DistanceShore <- runif(n,0.1,2)
samples=data.frame(theta=theta,DistanceShore=DistanceShore)

#define grid of values
theta_v <- seq(-pi,pi,length=30)
Dshore_v<- seq(0.2,8,length=30)
pr <- data.frame(theta=rep(theta_v,30),DistanceShore=rep(Dshore_v,rep(30,30)))


#points on the surface perturbed by gaussian noise
f <- fomega(samples)
y <- f+0.1*rnorm(n)


#fit with bivariate splines te
m1 <- gam(y~te(theta,DistanceShore,k=SP_DF),knots=list(theta=seq(-pi,pi,len=SP_DF),
                                                       DistanceShore=seq(0.02,7,len=SP_DF)))

ExpShore=1/DistanceShore

#fit with bivariate splines te
m2 <- gam(y~te(theta,ExpShore,k=SP_DF),knots=list(theta=seq(-pi,pi,len=SP_DF),
                                                  ExpShore=seq(1/8,1/0.2,len=SP_DF)))


fomega_cubic_splines=function(cov_data) {
  
  if (is.null(cov_data$ExpShore)){
    omega=predict(m1,newdata=cov_data)
  }
  else if (is.null(cov_data$DistanceShore)){
    omega=predict(m2,newdata=cov_data)
  }
  
  return(as.numeric(omega))
}

m1$sp
```


 ### Low frequency high error

```{r fit sde model with splines,cache=TRUE}


formulas <- list(mu1=~1,mu2=~1,tau=~1,
                 nu=~1,omega=~te(theta,DistanceShore,k=SP_DF,bs=c("cs")))


crcvm_splines_lf_he<- SDE$new(formulas = formulas,data = data_lf_he,type = "RACVM_SSM",
                    response = c("y1","y2"),par0 = PAR0_RACVM,fixpar=c("mu1","mu2"),
                    other_data=list("log_sigma_obs0"=log(0.05)))

crcvm_splines_lf_he$update_map(list("log_lambda"=factor(c(rep(NA,2)))))
crcvm_splines_lf_he$update_lambda(m1$sp)
#fit
crcvm_splines_lf_he$fit(method="BFGS")
```

```{r plot estimates}

crcvm_splines_lf_he$get_all_plots(show_CI="pointwise",true_smooths=list("omega"=fomega))

exp(as.list(crcvm_splines_lf_he$tmb_rep(),what="Estimate")$log_sigma_obs)

```


We are clearly underestimating the magnitude of the rotation $\omega$ near $-\pi$ and $\pi$. This is indeed very similar to the result we got for the narwhal GPS data. We are well estimating $\nu$ and $\sigma_{obs}$, and we corrected the bias in $\tau$ compared to the estimate we got for the CTCRW on the same data.
We can try to fit the true parametric function on the estimated spline surface.

```{r}


estimate_parametric_omega=function(model) {
    
    data=model$data()
    
    Dshore=seq(from=quantile(data$DistanceShore,0.5),to=quantile(data$DistanceShore,0.95),length.out=30)
    theta=seq(from=-pi,to=pi,length.out=30)
    grid<- as.data.frame(expand.grid(Dshore,theta))
    colnames(grid) <- c("DistanceShore","theta")
    grid$ID=1
    
    #get model matrices
    mats=model$make_mat(new_data=grid)
    X_fe=mats$X_fe
    X_re=mats$X_re
    
    par_mat=model$par(new_data=grid,X_fe=X_fe,X_re=X_re)
    
    #matrix of values for surface plot
    z=matrix(par_mat[,"omega"],30,30)
    
    data=grid
    data$z=as.vector(z)
    
    
    # Create the 3D surface plot using plot_ly
    plot_splines<- plot_ly(x = ~theta, y = ~Dshore, z = ~z) %>%
      add_surface() %>%
      layout(title = "Predicted spline surface for omega",
             scene = list(yaxis = list(title = "Distance to shore"),
               xaxis = list(title = "theta")))
    
    
    
    fit_optim <- optim(par = c(0.1,2),
                       fn = function(params) {
                         
                        # Compute predicted z values
                        z_pred <- fomega_cubic(data,A,B,params[1],params[2],SIGMA_D,SIGMA_THETA)
                         
                         # Return sum of squared residuals
                         sum((data$z - z_pred)^2)
                       })
    
    
    est_par=fit_optim$par
    
    # Compute the predicted values using the starting parameters
    z_pred_starting <- fomega_cubic(grid,A,B,est_par[1],est_par[1],SIGMA_D,
                                    SIGMA_THETA)
    
    # Reshape z_pred_starting to a matrix for plotting
    z_pred_matrix <- matrix(z_pred_starting, nrow = length(Dshore), ncol = length(theta))
    
    
    
    # Create the 3D surface plot using plot_ly
    plot_parametric <- plot_ly(x = ~theta, y = ~Dshore, z = ~z_pred_matrix) %>%
      add_surface() %>%
      layout(title = "Estimated parametric surface for omega",
             scene = list(
               yaxis = list(title = "Distance to shore"),
               xaxis = list(title = "theta"),
               zaxis = list(title = "Predicted z")
             ))
    
    return (list("est_par"=est_par,"splines_surface"=plot_splines,"parametric_surface"=plot_parametric))
    
}

estimate_parametric_omega(crcvm_splines_lf_he)

```




### Low frequency low error

```{r fit sde model with splines,cache=TRUE}


crcvm_splines_lf_le<- SDE$new(formulas = formulas,data = data_lf_le[data_lf_le$ID %in% c(1:6),],type = "RACVM_SSM",
                    response = c("y1","y2"),par0 = PAR0_RACVM,fixpar=c("mu1","mu2"),
                    other_data=list("log_sigma_obs0"=log(0.05)))

crcvm_splines_lf_le$update_map(list("log_lambda"=factor(rep(NA,2))))
crcvm_splines_lf_le$update_lambda(m1$sp)
#fit
crcvm_splines_lf_le$fit(method="BFGS")
```

```{r plot estimates}

crcvm_splines_lf_le$get_all_plots(show_CI="pointwise",true_smooths=list("omega"=fomega))

exp(as.list(crcvm_lf_le$tmb_rep(),what="Estimate")$log_sigma_obs)

```

```{r}
estimate_parametric_omega(crcvm_splines_lf_le)
```

Again, having low measurement error is not really of any help in the estimation. It is probably even more difficult to estimate since errors can occur in the matrix inversions in the Kalman filter when the coefficients in the covariance matrix are too close to $0$.

### High frequency high error

```{r fit sde model high frequency,cache=TRUE}


formulas <- list(mu1=~1,mu2=~1,tau=~1,
                 nu=~1,omega=~te(theta,DistanceShore,k=SP_DF,bs="cs"))


crcvm_splines_hf_he<- SDE$new(formulas = formulas,data = data_hf_he[data_hf_he$ID %in% 1:2,],type = "RACVM_SSM",
                    response = c("y1","y2"),par0 = PAR0_RACVM,fixpar=c("mu1","mu2"),
                    other_data=list("log_sigma_obs0"=log(0.05)))

#initialize smoothing penalties and re variances
new_lambda=c(m1$sp)
crcvm_splines_hf_he$update_lambda(new_lambda)


crcvm_splines_hf_he$update_map(list(log_lambda=factor(c(NA,NA))))

#fit
crcvm_splines_hf_he$fit(method="BFGS")
```


```{r}

crcvm_splines_hf_he$get_all_plots(show_CI="pointwise",true_smooths=list("omega"=fomega))


```

```{r}

estimate_parametric_omega(crcvm_splines_hf_he)

```

### High frequency low error

```{r fit sde model high frequency,cache=TRUE}




formulas <- list(mu1=~1,mu2=~1,tau=~1,
                 nu=~1,omega=~te(theta,DistanceShore,k=SP_DF,bs="cs"))


crcvm_splines_hf_le<- SDE$new(formulas = formulas,data = data_hf_le[data_hf_le$ID %in% 1:1,],type = "RACVM_SSM",
                    response = c("y1","y2"),par0 = PAR0_RACVM,fixpar=c("mu1","mu2"),
                    other_data=list("log_sigma_obs0"=log(0.05)))

#initialize smoothing penalties and re variances
new_lambda=c(m1$sp)
crcvm_splines_hf_le$update_lambda(new_lambda)


crcvm_splines_hf_le$update_map(list(log_lambda=factor(c(NA,NA))))

#fit
crcvm_splines_hf_le$fit(method="BFGS")
```


```{r}
crcvm_splines_hf_le$get_all_plots(show_CI="pointwise",true_smooths=list("omega"=fomega))


```


```{r}

estimate_parametric_omega(crcvm_splines_hf_le)
```

## Estimation with fixed parametric omega function

### Low frequency high error

We will fix the new parameters that are introduced in the model, and estimate the others, that is $\tau$ and $\nu$.
These new parameters might be chosen based on the observed distance to shore and observed angular velocity in the data.

```{r}
H=array(rep(SIGMA_OBS_HIGH^2*diag(2),length(data_lf_he$time)),dim=c(2,2,length(data_lf_he$time)))
# Estimate from simulated data ------------------

formulas <- list(tau=~1,
                 nu=~1,a=~1,b=~1,D0=~1,D1=~1,sigma_D=~1,sigma_theta=~1)

crcvm_cubic_lf_he<- SDE$new(formulas = formulas,
                            data = data_lf_he,type = "CRCVM_SSM",
                    response = c("y1","y2"),par0 = c(1,1,A,B,D0,D1,SIGMA_D,SIGMA_THETA),
                    fixpar=c("a","b","D0","D1","sigma_D","sigma_theta"),
                    other_data=list("H"=H))


#fit
crcvm_cubic_lf_he$fit(method="BFGS")
```

```{r}

crcvm_cubic_lf_he$get_all_plots(show_CI="simultaneous")
exp(as.list(crcvm_cubic_lf_he$tmb_rep(),what="Estimate")$log_sigma_obs)

```

We are unable to estimate $\tau$ while fixing $\omega$. $\tau$ is totally biased and underestimated, even more than when we neglected the constraints and used a simple CTCRW..

### Low frequency low error 

```{r}
H=array(rep(SIGMA_OBS_LOW^2*diag(2),length(data_lf_le$time)),dim=c(2,2,length(data_lf_le$time)))
# Estimate from simulated data ------------------

formulas <- list(tau=~1,
                 nu=~1,a=~1,b=~1,D0=~1,D1=~1,sigma_D=~1,sigma_theta=~1)

crcvm_cubic_lf_le<- SDE$new(formulas = formulas,data = data_lf_le[data_lf_le$ID %in% c(1:4),],
                              type = "CRCVM_SSM",
                    response = c("y1","y2"),par0 = c(1,1,A,B,D0,D1,SIGMA_D,SIGMA_THETA),fixpar=c("a","b","D0","D1","sigma_D","sigma_theta"),
                    other_data=list("H"=H))

crcvm_cubic_lf_le$fit(method="BFGS")
```
```{r}

crcvm_cubic_lf_le$get_all_plots(show_CI="simultaneous")
exp(as.list(crcvm_cubic_lf_le$tmb_rep(),what="Estimate")$log_sigma_obs)

```
Let's now try with high frequency data.

### High frequency high error

```{r}
H=array(rep(SIGMA_OBS_HIGH^2*diag(2),length(data_hf_he$time)),dim=c(2,2,length(data_hf_he$time)))

formulas <- list(tau=~1,
                 nu=~1,a=~1,b=~1,D0=~1,D1=~1,sigma_D=~1,sigma_theta=~1)


crcvm_cubic_hf_he<- SDE$new(formulas = formulas,data = data_hf_he[data_hf_he$DistanceShore>0.01 & data_hf_he$ID %in% c(1:6),],type = "CRCVM_SSM",
                    response = c("y1","y2"),par0 =c(1,1,A,B,D0,D1,SIGMA_D,SIGMA_THETA),
                    fixpar=c("a","b","D0","D1","sigma_D","sigma_theta"),
                    other_data=list("H"=H))

crcvm_cubic_hf_he$fit(method="BFGS")
```

```{r}
crcvm_cubic_hf_he$get_all_plots()
exp(as.list(crcvm_cubic_hf_he$tmb_rep(),what="Estimate")$log_sigma_obs)
```


### High frequency low error

```{r}

H=array(rep(SIGMA_OBS_LOW^2*diag(2),length(data_hf_le$time)),dim=c(2,2,length(data_hf_le$time)))

formulas <- list(tau=~1,
                 nu=~1,a=~1,b=~1,D0=~1,D1=~1,sigma_D=~1,sigma_theta=~1)


crcvm_cubic_hf_le<- SDE$new(formulas = formulas,data = data_hf_le[data_hf_le$ID %in% c(1:4),],
                            type = "CRCVM_SSM",
                    response = c("y1","y2"),par0 = c(1,1,A,B,D0,D1,SIGMA_D,SIGMA_THETA),
                    fixpar=c("a","b","D0","D1","sigma_D","sigma_theta"),
                    other_data=list("H"=H))

#fit
crcvm_cubic_hf_le$fit(method="BFGS")
```

```{r}
crcvm_cubic_hf_le$get_all_plots()
exp(as.list(crcvm_cubic_hf_le$tmb_rep(),what="Estimate")$log_sigma_obs)
```

```{r}
ggplot()+geom_point(data=data_hf_le,aes(time,theta),col="blue",alpha=0.5,size=0.1)+
  geom_point(data=data,aes(time,theta),col="red",alpha=0.2,size=0.1)+facet_wrap(~ID)

```
```{r}
data_hf_le$omega=fomega(data_hf_le[,c("theta","DistanceShore")])

ggplot()+geom_point(data=data_hf_le,aes(time,omega),col="blue",alpha=0.5,size=0.1)+
  geom_point(data=data,aes(time,omega),col="red",alpha=0.2,size=0.1)+facet_wrap(~ID)
```

