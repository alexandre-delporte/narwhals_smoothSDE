---
title: "Final analysis of Greenland narwhals trajectories with smoothSDE"
author: "Alexandre Delporte"
date: "2024-06-07"
output: html_document
---

In this analysis, we introduce covariates \texttt{AngleNormal} and 
\texttt{Ishore} ($\Theta$ and $I_{shore}$) in the SDE models for 
the narwhal data.
This allows to better understand how the fjords shoreline influences 
the narwhals movement in the baseline model.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Set up

```{r packages,message=FALSE}
set.seed(42)

library(smoothSDE)
library(ggplot2)
library(ggpubr)
library(patchwork)
library(dplyr)
library(plotly)
library(htmlwidgets)
library(mgcv)
library(here)
library(xtable)
library(sf)
library(purrr)
library(gganimate) # animated trajectories
library(doParallel)
library(foreach)
source(file.path(here("R","simulation_study_CRCVM","CVM_functions.R"))) 
```

```{r get data,message=FALSE}

# Set the path to the directory containing the data
par_dir=here() #parent directory 
narwhal_data_path <- file.path(par_dir,
                               "Data","preprocessed_data","narwhals")  

#data before exposure with first 24h removed
dataBE24=read.csv(file.path(narwhal_data_path,"DataBE24.csv"),
                  header = TRUE,dec = ".")

#data before exposure with first 12h removed
dataBE12=read.csv(file.path(narwhal_data_path,"DataBE12.csv"),
                  header = TRUE,dec = ".")

#data after exposure
dataAE=read.csv(file.path(narwhal_data_path,"DataAE.csv"),
                header = TRUE,dec = ".")

```

We choose thresholds on the distance to the shore
to define the Ishore covariate.


```{r preprocess data}


D_low=0.05
D_up=3
dataBE24[dataBE24$DistanceShore> D_up,"Ishore"]=0
dataBE24[dataBE24$DistanceShore< D_low,"Ishore"]=1/D_low

dataBE24[dataBE24$DistanceShore_translated> D_up,"Ishore_translated"]=0
dataBE24[dataBE24$DistanceShore_translated< D_low,"Ishore_translated"]=1/D_low

dataBE12[dataBE12$DistanceShore> D_up,"Ishore"]=0
dataBE12[dataBE12$DistanceShore< D_low,"Ishore"]=1/D_low

dataBE12[dataBE12$DistanceShore_translated> D_up,"Ishore_translated"]=0
dataBE12[dataBE12$DistanceShore_translated< D_low,"Ishore_translated"]=1/D_low


dataAE[dataAE$DistanceShore> D_up,"Ishore"]=0
dataAE[dataAE$DistanceShore< D_low,"Ishore"]=1/D_low


dataAE[dataAE$DistanceShore_translated> D_up,"Ishore_translated"]=0
dataAE[dataAE$DistanceShore_translated< D_low,"Ishore_translated"]=1/D_low

N=length(unique(dataBE12$ID))

n_pre12=length(dataBE12$time) #number of observations before exposure
n_pre24=length(dataBE24$time) #number of observations before exposure
n_post=length(dataAE$time) #number of observations after exposure
```


We bind data before exposure and after exposure in a single dataframe.

```{r bind data before and after exposure}

all_data <- data.frame()


for (id in unique(dataBE12$ID)) {
 
  sub_dataBE <- dataBE12[dataBE12$ID == id, ]
  sub_dataAE <- dataAE[dataAE$ID == id, ]
  
  sub_data <- rbind(sub_dataBE, sub_dataAE)
  
  all_data <- rbind(all_data, sub_data)
}

```


# Interpolate every minute



```{r smooth and interpolate trajectories}
smooth_interpolate <- function(df) {
  
  # Create a sequence of regular time points (every minute)
  time_seq <- seq(min(df$time), max(df$time), by = 1/30)
  
  # Fit smoothing splines
  smooth_x <- smooth.spline(df$time, df$x)
  smooth_y <- smooth.spline(df$time, df$y)
  
  # Predict at regular intervals
  interp_x <- predict(smooth_x, as.numeric(time_seq))$y
  interp_y <- predict(smooth_y, as.numeric(time_seq))$y
  
  # Return the interpolated data
  data.frame(time = time_seq, x = interp_x, y = interp_y, ID = unique(df$ID))
}


# Apply the function for each ID
interpolated_dataBE12 <- dataBE12 %>%
  group_by(ID) %>%
  group_split() %>%
  map_dfr(smooth_interpolate)

# Plot the original and smoothed trajectories by ID
plot_interpolation=ggplot() +
  geom_point(data = dataBE12, aes(x = x, y = y, color = factor(ID)), size = 2) +
  geom_path(data = interpolated_dataBE12, aes(x = x, y = y, color = factor(ID))) +
  theme_minimal() +
  labs(color = "Trajectory ID") +
  ggtitle("GPS points and splines interpolation")
```

# Compute Dshore and theta from interpolation

```{r}

signed_angle <- function(u, v) {
  #Compute signed angle in [-pi,pi] that rotates first vector into second vector 
  # as in 
  # https://math.stackexchange.com/questions/529555/signed-angle-between-2-vectors
  u <- matrix(u, ncol = 2)
  v <- matrix(v, ncol = 2)
  if (nrow(u) != nrow(v)) stop("u and v must have the same number of 
                                  rows")
  result <- as.numeric(atan2(v[,2], v[,1]) - atan2(u[,2], u[,1]))
  ind1 <- which(result > pi)
  ind2 <- which(result <= -pi)
  result[ind1] <- result[ind1] - 2*pi
  result[ind2] <- result[ind2] + 2*pi
  return(result) 
} 


add_covs_parallel <- function(data, n_cores = parallel::detectCores() - 1) {
  # Setup parallel backend
  cl <- makeCluster(n_cores)
  registerDoParallel(cl)
  
  # Split data by ID
  ids <- unique(data$ID)
  
  # Process each ID in parallel
  results <- foreach(id = ids, .combine = rbind, .packages = c("sf"),
                     .export = c("nearest_boundary_points", "is_in_land", "signed_angle","border",
                                 "D_low","D_up")  ) %dopar% {
                                   # Filter data for the current ID
                                   sub_data <- data[data$ID == id, ]
                                   n_sub <- nrow(sub_data)
                                   
                                   # Time steps
                                   dtimes <- sub_data[2:n_sub, "time"] -sub_data[1:(n_sub - 1), "time"]
                                   
                                   # Step lengths
                                   dx <- sub_data[2:n_sub, "x"] - sub_data[1:(n_sub - 1), "x"]
                                   dy <- sub_data[2:n_sub, "y"] - sub_data[1:(n_sub - 1), "y"]
                                   
                                   # Empirical velocity
                                   vexp_df <- cbind(dx / dtimes, dy / dtimes)
                                   
                                   # Nearest points on shore
                                   sub_data <- cbind(sub_data, nearest_boundary_points(as.matrix(sub_data[, c("x", "y")]), border))
                                   
                                   # Normal vectors
                                   normal <- as.matrix(sub_data[2:n_sub, c("x", "y")] - sub_data[2:n_sub, c("p1", "p2")])
                                   
                                   # Angle between velocity and normal vector
                                   theta_coast <- signed_angle(normal, vexp_df)
                                   theta_coast <- c(theta_coast, 1)  # Adjust length
                                   
                                   # Initialize DistanceShore
                                   Dshore <- rep(0, n_sub)
                                   
                                   for (i in 1:n_sub) {
                                     y1 <- sub_data[i, "x"]
                                     y2 <- sub_data[i, "y"]
                                     if (!is_in_land(st_point(c(y1, y2)), border)) {
                                       p1 <- sub_data[i, "p1"]
                                       p2 <- sub_data[i, "p2"]
                                       Dshore[i] <- sqrt((y1 - p1)^2 + (y2 - p2)^2)
                                     }
                                   }
                                   
                                   # Calculate Ishore
                                   Ishore <- ifelse(Dshore < D_low, 1 / D_low, ifelse(Dshore > D_up, 0, 1 / Dshore))
                                   
                                   # Add columns to sub_data
                                   sub_data$theta <- theta_coast
                                   sub_data$DistanceShore <- Dshore
                                   sub_data$Ishore <- Ishore
                                   
                                   return(sub_data)
                                 }
  
  # Stop the cluster
  stopCluster(cl)
  
  return(results)
}

interpolated_dataBE12=add_covs_parallel(interpolated_dataBE12)

```

# Fit baseline models

We try sde models where the parameters are smooth function 
of the covariates theta and Ishore.
Here, for simplicity we will always fix the measurement error to $50$ m. 
This choice is based on the paper of Weensven.
We will assess the sensitivity of our results to the hyperparameter later.



## Baseline CTCRW with AngleNormal covariate in $\tau$

The first model is a CTCRW where the covariate theta influences 
the persistence of the movement.

```{r fit baseline_ctcrw0,message=FALSE}

#initial parameters
par0 <- c(0,0,1,4)

#model formula
formulas <- list(mu1=~1,mu2=~1,tau =~s(theta,k=10,bs="cc")+s(ID,bs="re"),nu=~s(ID,bs="re"))

#Fixed measurement error
sigma_obs=0.01
H=array(rep(sigma_obs^2*diag(2),length(interpolated_dataBE12$time)),dim=c(2,2,length(interpolated_dataBE12$time)))

#Fit baseline with measurement error estimated from the data
baseline_ctcrw0<- SDE$new(formulas = formulas,data = interpolated_dataBE12,type = "CTCRW",
                          response = c("x","y"),
                          par0 = par0,
                          other_data=list("H"=H),
                          fixpar=c("mu1","mu2"))
baseline_ctcrw0$fit()

```

```{r define function to get raw estimates}
# Function to extract estimate values into a data frame format
combine_to_df <- function(estimates, std_dev, param_name) {
  data.frame(
    Parameter = param_name,
    Estimate = unlist(estimates, use.names = FALSE),
    Std_Error = unlist(std_dev, use.names = FALSE)
  )
}

make_raw_latex_tab<- function(sde) {
  
  estimates=as.list(sde$tmb_rep(),what="Est")
  std=as.list(sde$tmb_rep(),what="Std")
  
  # Create data frames for each set
  log_sigma_obs <- combine_to_df(estimates$log_sigma_obs, 
                                 std$log_sigma_obs, "log_sigma_obs")
  coeff_fe <- combine_to_df(estimates$coeff_fe,
                            std$coeff_fe, 
                            rownames(estimates$coeff_fe))
  
  coeff_re <- combine_to_df(estimates$coeff_re,
                            std$coeff_re, 
                            rownames(estimates$coeff_re))
  
  log_lambda <- combine_to_df(estimates$log_lambda,
                            std$log_lambda, 
                            rownames(estimates$log_lambda))
  
  # Combine all data frames into one
  table_data <- bind_rows(log_sigma_obs, coeff_fe,coeff_re,log_lambda)
  
  latex_table <- xtable(table_data, 
                        caption = "Parameter Estimates and Standard Errors")
  

  print(latex_table, type = "latex", include.rownames = FALSE)
  
}

```

```{r raw estimates baseline_ctcrw0}
make_raw_latex_tab(baseline_ctcrw0)
```


We can get confidence intervals for the intercept 
of each parameter and the random effects standard deviations.

```{r define function to get final results}

get_baseline_estimates<- function(sde,include_sigma_obs=FALSE) {
  
  post_coeff=sde$post_coeff(n_post=10000)
  post_par=list(
  "tau"=exp(post_coeff$coeff_fe[,"tau.(Intercept)"]),
  "nu"=exp(post_coeff$coeff_fe[,"nu.(Intercept)"]),
  "sigma_tau"=1/sqrt(exp(post_coeff$log_lambda[,"tau.s(ID)"])),
  "sigma_nu"=1/sqrt(exp(post_coeff$log_lambda[,"nu.s(ID)"])))
  
  if (include_sigma_obs) {
    post_par$sigma_obs=1000*exp(post_coeff$log_sigma_obs)
  }

  mean_par=lapply(post_par,mean)
  sd_par=lapply(post_par,sd)
  quant_par <- lapply(post_par,
                      quantile, probs = c(0.025, 0.975))
  
  return(list("estimates"=mean_par,"std.error"=sd_par,"quantiles"=quant_par))
  
}

make_final_baseline_tab<-function(sde,include_sigma_obs=FALSE) {
  
  est=get_baseline_estimates(sde,include_sigma_obs)
  mean_par=est$estimates
  sd_par=est$std.error
  quant_par=est$quantiles
  parameter_names <- names(mean_par)
  estimates <- mean_par
  conf_intervals <- sapply(parameter_names, function(param) {
  sprintf("$[%.2f; %.2f]$", quant_par[[param]][1], 
          quant_par[[param]][2])
    })
  
  parameter_names=c("$\\tau$", "$\\nu$","$\\sigma_{\\tau}$","$\\sigma_{\\nu}$")
  if (include_sigma_obs) {
    parameter_names=c(parameter_names,"$\\sigma_{\\obs}$")
  }
  table_data <- data.frame(
    Parameter = parameter_names,
  Estimate = sprintf("$%.2f$", mean_par),
  CI = conf_intervals,
  stringsAsFactors = FALSE)
  
  xtab <- xtable(
  table_data,
  caption = paste(sde$type(),"baseline estimations with random effects"),
  label = paste0("table:",sde$type(),"_baseline_estimations_with_random_effects"))
  
  print(
  xtab,type="latex",
  include.rownames = FALSE,
  sanitize.text.function = identity,  # Prevent escaping of LaTeX math symbols
  hline.after = c(-1, 0, nrow(table_data)),  
  table.placement="H")

} 


```

```{r final estimates baseline_ctcrw0, message=FALSE}


make_final_baseline_tab(baseline_ctcrw0,include_sigma_obs=FALSE)


```


We can now plot the smooth parameter $\tau$ as a 
function of the covariate \texttt{AngleNormal}.

```{r plot smooth parameters baseline_ctcrw0 }
baseline_ctcrw0$plot_par(var="theta",
                         par_names=c("tau","nu"),n_post=100)

```

```{r plot smooth parameters CI baseline_ctcrw0}
baseline_ctcrw0$get_all_plots(baseline=NULL,show_CI="simultaneous")
```

The movement is clearly more persistent along the shoreline, meaning
that $\tau$ increases when \texttt{AngleNormal} is close to $\pm \frac{\pi}{2}$). 



## Baseline racvm with $\Theta$ covariate in tau and omega

We now decide to introduce a rotational parameter $\omega$ in the SDE to
allow the velocity to rotate depending on the narwhals position with 
respect to the shoreline.
We start by introducing the covariate \texttt{theta} in the new smooth 
parameter $\omega$ to understand how the animals may rotate depending on 
the direction of their movement with respect to the shoreline.

```{r fit baseline_racvm0,cache=TRUE}

#initial parameters
par0 <- c(0,0,1,4,0)

#model formula
formulas <- list(mu1=~1,mu2=~1,
                 tau =~s(theta_translated,k=10,bs="cc")+s(ID,bs="re"),
                 nu=~s(ID,bs="re"),
                 omega=~s(theta_translated,k=5,bs="cs"))


# Fit baseline with measurement error estimated from the data
baseline_racvm0<- SDE$new(formulas = formulas,data = dataBE12,
                          type = "RACVM_SSM",response = c("x","y"),
                    par0 = par0,other_data=list("H"=H),fixpar=c("mu1","mu2"))

baseline_racvm0$fit()



```


```{r raw estimates baseline_racvm0}
make_raw_latex_tab(baseline_racvm0)
```



```{r final estimates baseline_racvm0, message=FALSE}

make_final_baseline_tab(baseline_racvm0,include_sigma_obs=FALSE)

```

```{r plot smooth parameters baseline_racvm0}
baseline_racvm0$plot_par(var="theta_translated",
                         par_names=c("omega","tau"),n_post=100)

```

$\omega$ close to $\pm \pi$ indicates movement toward the shoreline.
Here, it seems that the narwhals have a slight tendency to rotate,
presumably to move along the shoreline or change direction, 
when they are heading toward the shore.
However, it is not very clear since the confidence intervals are wide.

```{r plot smooth parameter CI baseline_racvm0}
baseline_racvm0$get_all_plots(baseline=NULL,show_CI="pointwise")
```


## Baseline with theta and DistanceShore in $\omega$ and $\tau$

We add the effect of the distance to the shore 
through the covariate \texttt{Ishore_translated}.
This model has a lot of parameters and takes around 15 minutes to fit. 
Indeed, we will need to fix the penalties in the tensor splines in 
advance to ensure convergence of the optimizer. 
The standard deviation of the random effects and the smoothing penalties 
for the splines in $\tau$ will still be estimated from the data and not fixed.
To illustrate this we first fit a model where the smoothing penalties 
are all estimated from the data.


```{r fit baseline_racvm1_unstable,cache=TRUE,message=FALSE}

#initial parameters
par0 <- c(0,0,1,4,0)

#parameters formulas
formulas <- list(mu1 = ~1 ,mu2 =~1,tau =~s(theta_translated,k=10,bs="cc")+s(ID,bs="re"),nu=~s(ID,bs="re"),
                   omega=~te(theta_translated,Ishore_translated,k=5,bs="cs"))

# Fit baseline
baseline_racvm1_unstable<- SDE$new(formulas = formulas,data = dataBE12,type = "RACVM_SSM",
                    response = c("x","y"),par0 = par0,other_data=list("H"=H),
                    fixpar=c("mu1","mu2"))


baseline_racvm1_unstable$fit()



```


```{r std random effects baseline_racvm1_unstable}

baseline_racvm1_unstable$sdev()


```

The smoothing penalties estimates are extremely low (the smoothing penalties are
the inverse of the square root
of \texttt{omega.te(theta\_translated,Ishore\_translated)}).
This suggests that the optimization did not go well and numerical errors
occurred. For this reason, we decide to fix the smoothing penalties to 
"reasonable" values in the tensor splines.

First, we get good values for the smoothing penalty by approximating an 
expected "reasonable" surface with tensor splines, using the 
parametric function defined in the paper.

```{r get smooth penalty values}

fomega=function(cov_data,a=3,b=2,D0=0.4,D1=1,sigma_D=0.5,sigma_theta=pi/6){
  Dshore=cov_data$DistanceShore
  theta=cov_data$theta
  if (is.null(Dshore)){
    Dshore=1/cov_data$Ishore
  }
  
  a*theta*(theta-pi/2)*(theta+pi/2)*exp(-Dshore/D0)/Dshore+
      b*(exp(-1/2*(((theta+pi/2/sqrt(3))/sigma_theta)^2+
                     ((Dshore-D1)/sigma_D)^2))-
           exp(-1/2*(((theta-pi/2/sqrt(3))/sigma_theta)^2+
                       ((Dshore-D1)/sigma_D)^2)))
}

# Splines smooth for omega -------------------- 
n <- 100000
SP_DF=c(5,5)

#sample theta and DistanceShore points in the domain
theta <- runif(n,-pi,pi);
DistanceShore <- runif(n,0.05,3)
samples=data.frame(theta=theta,DistanceShore=DistanceShore)

#define grid of values
theta_v <- seq(-pi,pi,length=30)
Dshore_v<- seq(0.05,3,length=30)
pr <- data.frame(theta=rep(theta_v,30),DistanceShore=rep(Dshore_v,rep(30,30)))


#points on the surface perturbed by gaussian noise
f <- fomega(samples)
y <- f+0.1*rnorm(n)

Ishore=1/DistanceShore

#fit with bivariate splines te
m1 <- gam(y~te(theta,Ishore,k=SP_DF,bs=c("cs")))

```

```{r fit baseline_racvm1,cache=TRUE}

#initial parameters
par0 <- c(0,0,1,4,0)
init_lambda=c(exp(3),exp(3),1,m1$sp)

#mapping for fixed smoothing penalties
new_map=list("log_lambda"=factor(c(1,2,3,rep(NA,2))))


#parameters formulas
formulas <- list(mu1 = ~1 ,mu2 =~1,
                 tau =~s(theta_translated,k=10,bs="cc")+s(ID,bs="re"),
                 nu=~s(ID,bs="re"),
                   omega=~te(theta_translated,Ishore_translated,k=c(5,5),bs="cs"))

# Fit baseline
baseline_racvm1<- SDE$new(formulas = formulas,data = dataBE12,type = "RACVM_SSM",
                    response = c("x","y"),par0 = par0,other_data=list("H"=H),
                    fixpar=c("mu1","mu2"))

baseline_racvm1$update_lambda(init_lambda)
baseline_racvm1$update_map(new_map)
baseline_racvm1$fit()


```


```{r raw estimates baseline_racvm1}
make_raw_latex_tab(baseline_racvm1)
```

```{r final estimates baseline_racvm1, message=FALSE}

make_final_baseline_tab(baseline_racvm1,include_sigma_obs=FALSE)

```

```{r display plots baseline_racvm1}

Ishore_values=c(1/0.25,1/2,1/10)
plots=lapply(1:length(Ishore_values),function(i){
  baseline_racvm1$plot_par(
    var="theta_translated",
    covs=data.frame("ID"="Asgeir","Ishore_translated"=Ishore_values[i]),
    par_names=c("omega"),n_post=100)})

plots

```

```{r plot smooth parameters CI baseline_racvm1}

#plot parameters

xmin=list("Ishore_translated"=1/3)
xmax=list("Ishore_translated"=1/0.3)
link=list("Ishore_translated"=\(x) 1/x)
xlabel=list("Ishore_translated"="DistanceShore")

plots_bas_racvm1=baseline_racvm1$get_all_plots(baseline=NULL,
      xmin=xmin,xmax=xmax,link=link,xlabel=xlabel,show_CI="pointwise")

plots_bas_racvm1


```

```{r save plots baseline_racvm1}
# Create directory
if (!dir.exists("baseline_racvm1")) {
    dir.create("baseline_racvm1", recursive = TRUE)
}

# Use lapply to save each plot
lapply(seq_along(plots_bas_racvm1), function(i) {
    
    plot<-plots_bas_racvm1[[i]]
    plot_name <- names(plots_bas_racvm1)[i]
    file_path <- file.path("baseline_racvm1", plot_name)
    
    # Check if the plot is a ggplot or plotly object
    if (inherits(plot, "ggplot")) {
      ggsave(file_path, plot, device = "pdf")
    } else if (inherits(plot, "plotly")) {
      saveWidget(plot, file_path)
  }
    })
```


Now, we would like to demonstrate how the Distance to shore 
influences the smooth parameter $\omega$.
We plot the estimated smooth parameter $\omega$ as a function 
of the angle for different values of the Distance to shore.

```{r smooth omega baseline_racvm1}

get_shore_influence_plot<-function(sde) {
  
  
  xmin=list("Ishore_translated"=1/2)
  xmax=list("Ishore_translated"=1/0.2)
  link=list("Ishore_translated"=\(x) 1/x)
  xlabel=list("Ishore_translated"="DistanceShore")
  
  plots=sde$get_all_plots(baseline=NULL,
      xmin=xmin,xmax=xmax,link=link,xlabel=xlabel,show_CI="pointwise")
  
  plot1=plots$fe_omega_theta_translated_q1_Ishore_translated
  plot2=plots$fe_omega_theta_translated_q2_Ishore_translated
  plot4=plots$fe_omega_theta_translated_q4_Ishore_translated

  omega1 <- ggplot_build(plot1)$data[[1]]
  omega2 <- ggplot_build(plot2)$data[[1]]
  omega4 <- ggplot_build(plot4)$data[[1]]

  omega1$Category <- "Far"
  omega2$Category <- "Medium"
  omega4$Category <- "Close"

  # Combine the data frames
  combined_omega <- rbind(omega1, omega2, omega4)

  ci_omega1 <- ggplot_build(plot1)$data[[2]]
  ci_omega2 <- ggplot_build(plot2)$data[[2]]
  ci_omega4 <- ggplot_build(plot4)$data[[2]]

  ci_omega1$Category <- "Far"
  ci_omega2$Category <- "Medium"
  ci_omega4$Category <- "Close"

  # Combine the data frames
  combined_ci_omega <- rbind(ci_omega1, ci_omega2, ci_omega4)

  combined_plot <- ggplot() +
    geom_line(data=combined_omega, aes(x=x, y=y, color=Category, linetype=Category)) +
    geom_ribbon(data=combined_ci_omega, aes(x=x, ymin=ymin, ymax=ymax, fill=Category), alpha=0.1) +
    labs(color="Category", linetype="Category", x=expression(Theta), y=expression(omega)) +
    geom_vline(xintercept=c(-pi/2, pi/2), linetype="dashed", color="grey") +
    annotate("text", x = -pi/2-0.3, y = -5, label = expression(-pi/2), color = "red", size = 8) + 
    annotate("text", x = pi/2+0.2, y = -5, label = expression(pi/2), color = "red", size = 8) + 
    theme_minimal()+
   theme(
    axis.title.x = element_text(size=22),
    axis.title.y = element_text(size=22, angle=0, vjust=0.5, margin = margin(r = 10)),
    axis.text.x = element_text(size=18),
    axis.text.y = element_text(size=18),
    legend.title = element_text(size=18),
    legend.text = element_text(size=18)
  )
  
  return(combined_plot)
}

shore_influence_plot_baseline_racvm1=get_shore_influence_plot(baseline_racvm1)

ggsave("omega_DistanceShore_levels.pdf",
       plot=shore_influence_plot_baseline_racvm1,
       path="baseline_racvm1", width=10, height=6, units="in")



```

There seems to be a rotation close to the shore when the angle
$\Theta \in [-\pi,-\frac{\pi}{2}] \cup [\frac{\pi}{2},\pi]$, which means
movement toward the shore. However, again the confidence intervals are 
too wide to really conclude.
Moreover, we fixed the smoothing penalties in the tensor splines. 
Changing their values can influence the shape of the estimated functions :
lower values will produce functions that are more wiggily in each direction.




```{r define smooth parametric estimate baseline_racvm1}

estimate_parametric_omega=function(model,fixed_a=NULL,probs=c(0.5,0.95)) {
    
    data=model$data()
    
    Dshore=seq(from=quantile(data$DistanceShore_translated,probs[1]),
               to=quantile(data$DistanceShore_translated,probs[2]),length.out=30)
    Ishore=1/Dshore
    theta_translated=seq(from=-pi,to=pi,length.out=30)
    grid<- as.data.frame(expand.grid(Ishore,theta_translated))
    colnames(grid) <- c("Ishore_translated","theta_translated")
    grid$ID="Asgeir"
    grid$Dshore_translated=1/grid$Ishore_translated
    
    #get model matrices
    mats=model$make_mat(new_data=grid)
    X_fe=mats$X_fe
    X_re=mats$X_re
    
    par_mat=model$par(new_data=grid,X_fe=X_fe,X_re=X_re)
    
    #matrix of values for surface plot
    z=matrix(par_mat[,"omega"],30,30)
    
    data=grid
    data$z=as.vector(z)
    
    
    # Create the 3D surface plot using plot_ly
    plot_splines<- plot_ly(x = ~theta_translated, y = ~Dshore, z = ~z) %>%
      add_surface() %>%
      layout(title = "Predicted spline surface for omega",
             scene = list(yaxis = list(title = "Distance to shore"),
               xaxis = list(title = "theta_translated")))
    
    
    data_copy=data
    colnames(data_copy)=c("Ishore","theta","ID","DistanceShore","z")
    
    if (is.null(fixed_a)) {
      
      fit_optim <- optim(par = log(c(1,0.5,0.1,2,0.5,pi/6)),
                       fn = function(params) {
                         
                        # Compute predicted z values
                        z_pred <- fomega(data_copy,exp(params[1]),
                                         exp(params[2]),exp(params[3]),
                                         exp(params[4]),exp(params[5]),
                                         exp(params[6]))
                         
                         # Return sum of squared residuals
                         sum((data_copy$z - z_pred)^2)
                       })
      
    } 
    else {
    fit_optim <- optim(par = log(c(0.5,0.1,2,0.5,pi/6)),
                       fn = function(params) {
                         
                        # Compute predicted z values
                        z_pred <- fomega(data_copy,fixed_a,exp(params[1]),
                                         exp(params[2]),exp(params[3]),
                                         exp(params[4]),exp(params[5]))
                         
                         # Return sum of squared residuals
                         sum((data_copy$z - z_pred)^2)
                       })
    
    }
    est_par=fit_optim$par
    
    # Compute the predicted values using the estimated parameters
    if (is.null(fixed_a)) {
      
      z_pred_starting <- fomega(grid,exp(est_par[1]),
                              exp(est_par[2]),exp(est_par[3]),
                              exp(est_par[4]),exp(est_par[5]),
                              exp(est_par[6]))
      
      
    } else {
    z_pred_starting <- fomega(grid,fixed_a,
                              exp(est_par[1]),exp(est_par[2]),
                              exp(est_par[3]),exp(est_par[4]),
                              exp(est_par[5]))
    }
    
    # Reshape z_pred_starting to a matrix for plotting
    z_pred_matrix <- matrix(z_pred_starting, nrow = length(Dshore),
                            ncol = length(theta_translated))
    
    
    # Create the 3D surface plot using plot_ly
    plot_parametric <- plot_ly(x = ~theta_translated, y = ~Dshore,
                               z = ~z_pred_matrix) %>%
      add_surface() %>%
      layout(title = "Estimated parametric surface for omega",
             scene = list(
               yaxis = list(title = "Distance to shore"),
               xaxis = list(title = "theta"),
               zaxis = list(title = "Predicted z")
             ))
    
    return (list("est_par"=exp(est_par),"splines_surface"=plot_splines,
                 "parametric_surface"=plot_parametric))
    
}

res_racvm1=estimate_parametric_omega(baseline_racvm1,fixed_a=0.3)

res_racvm1
```



This model in indeed very complex and involves a large number of parameters 
given the amount of data points we have for the trajectories before exposure.
We can try to fit the exact same model on all the data to check if
we get the same kind of results with tighter confidence intervals.
Here, we fix the measurement error standard deviation because 
we get a non positive definite Hessian matrix in the optimization otherwise.



```{r fit all_racvm1,cache=TRUE}

#initial parameters
par0 <- c(0,0,1,4,0)
init_lambda=c(exp(5),exp(5),1,m1$sp)

#mapping for fixed smoothing penalties
new_map=list("log_lambda"=factor(c(1,2,3,rep(NA,2))))

#Fixed measurement error
sigma_obs=0.05
H=array(rep(sigma_obs^2*diag(2),length(all_data$time)),
        dim=c(2,2,length(all_data$time)))


#parameters formulas
formulas <- list(mu1 = ~1 ,mu2 =~1,
                 tau =~s(theta_translated,k=10,bs="cc")+s(ID,bs="re"),nu=~s(ID,bs="re"),
                   omega=~te(theta_translated,Ishore_translated,k=c(5,5),bs="cs"))

# Fit baseline
all_racvm1<- SDE$new(formulas = formulas,data = all_data,type = "RACVM_SSM",
                    response = c("x","y"),par0 = par0,other_data=list("H"=H),
                    fixpar=c("mu1","mu2"))

all_racvm1$update_lambda(init_lambda)
all_racvm1$update_map(new_map)
all_racvm1$fit()


```


```{r plot smooth parameters CI baseline_racvm1}

#plot parameters

xmin=list("Ishore_translated"=1/2)
xmax=list("Ishore_translated"=1/0.2)
link=list("Ishore_translated"=\(x) 1/x)
xlabel=list("Ishore_translated"="DistanceShore")

plots_all_racvm1=all_racvm1$get_all_plots(baseline=NULL,
      xmin=xmin,xmax=xmax,link=link,xlabel=xlabel,show_CI="pointwise")

plots_all_racvm1


```

```{r final estimates all_racvm1, message=FALSE}

make_final_baseline_tab(all_racvm1,include_sigma_obs=FALSE)

```


We now come back to the data before exposure and try a more parsimonious 
model by removing the dependence of $\tau$ on
the covariate \texttt{theta\_translated}.

## Baseline with theta and Ishore in omega 

```{r fit baseline_racvm2,cache=TRUE}

#initial parameters
par0 <- c(0,0,1,4,0)
init_lambda=c(exp(3),exp(3),m1$sp)

#mapping for fixed smoothing penalties
new_map=list("log_lambda"=factor(c(1,2,rep(NA,2))))


#Fixed measurement error
sigma_obs=0.01
H=array(rep(sigma_obs^2*diag(2),length(interpolated_dataBE12$time)),dim=c(2,2,length(interpolated_dataBE12$time)))

#parameters formulas
formulas <- list(mu1 = ~1 ,mu2 =~1,tau =~s(ID,bs="re"),nu=~s(ID,bs="re"),
                   omega=~te(theta,Ishore,k=c(5,5),bs=c("cs")))

# Fit baseline
baseline_racvm2<- SDE$new(formulas = formulas,data = interpolated_dataBE12,
                    type = "RACVM_SSM",response = c("x","y"),par0 = par0,
                    other_data=list("H"=H),fixpar=c("mu1","mu2"))

baseline_racvm2$update_lambda(init_lambda)
baseline_racvm2$update_map(new_map)
baseline_racvm2$fit()



```

```{r final estimates baseline_racvm2, message=FALSE}

make_final_baseline_tab(baseline_racvm2,include_sigma_obs=FALSE)

```


```{r display plots baseline_racvm2}

Ishore_values=c(1/0.25,1/2,1/5)
plots=lapply(1:length(Ishore_values),function(i){
  baseline_racvm2$plot_par(
    var="theta_translated",
    covs=data.frame("ID"="Asgeir","Ishore_translated"=Ishore_values[i]),
                         par_names=c("omega"),n_post=100)})
plots

```





```{r plot smooth parameters CI baseline_racvm2}
#plot parameters

xmin=list("Ishore"=1/3)
xmax=list("Ishore"=1/0.1)
link=list("Ishore"=\(x) 1/x)
xlabel=list("Ishore"="Distance to shore")

plots_bas_racvm2=baseline_racvm2$get_all_plots(baseline=NULL,
      xmin=xmin,xmax=xmax,link=link,xlabel=xlabel,show_CI="pointwise")

plots_bas_racvm2


```

```{r save plots baseline_racvm2}
# Create directory
if (!dir.exists("baseline_racvm2")) {
    dir.create("baseline_racvm2", recursive = TRUE)
}

# Use lapply to save each plot
lapply(seq_along(plots_bas_racvm2), function(i) {
    
    plot<-plots_bas_racvm2[[i]]
    plot_name <- names(plots_bas_racvm2)[i]
    file_path <- file.path("baseline_racvm2", plot_name)
    
    # Check if the plot is a ggplot or plotly object
    if (inherits(plot, "ggplot")) {
      ggsave(file_path, plot, device = "pdf")
    } else if (inherits(plot, "plotly")) {
      saveWidget(plot, file_path)
  }
    })
```


```{r smooth omega baseline_racvm2}

shore_influence_plot_baseline_racvm2=get_shore_influence_plot(baseline_racvm2)
ggsave("omega_DistanceShore_levels.pdf", plot=shore_influence_plot_baseline_racvm2,
       path="baseline_racvm2", width=10, height=6, units="in")

shore_influence_plot_baseline_racvm2

```

This baseline model seems quite satisfactory.
We can now try to fit the parametric function defined in the paper on the estimated spline surface.
We have seen in the simulation study that the splines give good estimates for $\omega$ provided we are not too close to
the shore. Thus we fit the parametric function on the spline surface cropped close to the shore.
We fix the value of $a$ to 0.5 to ensure that simulated trajectories will be constrained.

```{r get smooth parametric estimates baseline_racvm2}

res_racvm2=estimate_parametric_omega(baseline_racvm2,
                                     fixed_a=4,probs=c(0.75,0.95))

res_racvm2
```

To check the baseline model, we simulate trajectory using the estimated 
parameters, compare it to the observed data and use the simulated trajectory to 
estimate again the parameters. We check that the values estimated 
from the simulated trajectories are consistent with the values 
estimated from the data.


# Check baseline models

## Simulate trajectories using estimated parameters

```{r set up for simulation of trajectories,cache=TRUE}

#initial narwhals positions (convert to matrix to avoid bugs)
z0_BE <- as.matrix(dataBE12[!duplicated(dataBE12$ID), c("x", "y")])

# Get land polygons
par_dir=here()
greenland_data_path <- file.path(par_dir,"Data", 
                                 "preprocessed_data","greenland")  



land<-st_read(file.path(greenland_data_path,
                        "updated_scoresby_sound_utm.shp"))
land <- st_transform(land, crs = "+init=EPSG:32626 +units=km")

shrunk_land<-st_read(file.path(greenland_data_path,
                        "shrunk_updated_scoresby_sound_utm.shp"))
shrunk_land <- st_transform(shrunk_land, crs = "+init=EPSG:32626 +units=km")

# Simulate trajectories from adjusted model


# Define functions to compute covariates along the way
fangle=function(z,v,p) {
  
  #normal vector
  normal=c(z[1]-p[1],z[2]-p[2])
  
  #return angle
  return (signed_angle(normal,v))
}


fIshore=function(z,v,p) {
  
  
  #normal vector
  normal=c(z[1]-p[1],z[2]-p[2])
  
  #distance to shore
  Dshore=sqrt(normal[1]^2+normal[2]^2)
  if (Dshore>3){
    return (0)
  }
  else if (Dshore<0.2) {
    return (5)
  }
  else {
    return (1/Dshore)
  }
}


fDshore=function(z,v,p) {
  
  
  #normal vector
  normal=c(z[1]-p[1],z[2]-p[2])
  
  #distance to shore
  Dshore=sqrt(normal[1]^2+normal[2]^2)
  if (Dshore>0.005) {
      return(Dshore)
  }
  else {
    return(0.005)
  }

}



atw=list("Ishore"=fIshore,"Ishore_translated"=fIshore,
         "theta"=fangle,"theta_translated"=fangle,"DistanceShore"=fDshore)


# Define time steps
delta=1/60/6
times_list=lapply(unique(dataBE12$ID),function(ID) {
  min=min(dataBE12[dataBE12$ID==ID,"time"])
  max=max(dataBE12[dataBE12$ID==ID,"time"])
  seq(min,max,by=delta)})
names(times_list)=unique(dataBE12$ID)
times_df <- data.frame(
  ID = rep(names(times_list), sapply(times_list, length)),
  time = unlist(times_list),row.names = NULL
)
n=length(times_df$time)
# Define covariates data (needed in the function simulate)
data_reg=data.frame("Ishore"=rep(1,n),"Ishore_translated"=rep(1,n),
                    "theta"=rep(0,n),"DistanceShore"=rep(1,n),
                    "theta_translated"=rep(0,n))

data_reg=cbind(data_reg,times_df)

```



```{r,message=FALSE,results=console}

#set.seed(51)
set.seed(52)
est_par_racvm2=res_racvm2$est_par
fixed_a=4

formulas=list(tau=~s(ID,bs="re"),nu=~s(ID,bs="re"),a=~1,b=~1,D0=~1,D1=~1,
              sigma_D=~1,sigma_theta=~1)
baseline_crcvm2<-SDE$new(formulas=formulas,data=dataBE12,
                         type="CRCVM_SSM",response=c("x","y"),
               par0=c(baseline_racvm2$par()[1,c("tau","nu")],fixed_a,
                        est_par_racvm2))

baseline_crcvm2$update_coeff_re(baseline_racvm2$coeff_re()[1:12,])
baseline_crcvm2$update_lambda(baseline_racvm2$lambda()[1:2,])

baseline_crcvm2_trajectory=baseline_crcvm2$simulate(
  z0=z0_BE,data=data_reg,atw=atw,land=shrunk_land,verbose=FALSE)

n=length(baseline_crcvm2_trajectory$time)

baseline_crcvm2_trajectory_sub=baseline_crcvm2_trajectory[seq(1,n,by=60),]



plot_baseline_crcvm2_trajectory=ggplot() +
  geom_sf(data=shrunk_land$geometry,fill="grey")+
  coord_sf(datum=st_crs("+init=EPSG:32626 +units=km"))+
  geom_path(data=baseline_crcvm2_trajectory_sub, 
            aes(x = x, y = y,color=ID),size = 0.5, 
            lineend = "round",alpha=0.5) +     
  geom_point(data=baseline_crcvm2_trajectory_sub,
             aes(x = x, y = y,color=ID),size =0.5 ) +
  theme_minimal()+
  scale_color_viridis_d(labels=c("A1","A2","A3","A4","A5","A6"))+theme(
    axis.title = element_text(size = 18),
    axis.text = element_text(size = 14),
    legend.text = element_text(size = 18),
    axis.title.y = element_text(angle = 0)  # Rotate the y-axis label and adjust horizontal justification
  )



```



```{r}

baseline_crcvm2_trajectory_sub<- baseline_crcvm2_trajectory_sub %>% 
  mutate(data_type = "Simulated baseline_crcvm2")
observed_trajectory<- dataBE12%>% 
  mutate(data_type = "Observed")

baseline_trajectories <- bind_rows(baseline_crcvm2_trajectory_sub,
                                   observed_trajectory)

# Basic ggplot setup
plot_baseline_trajectories <- ggplot() +
  geom_sf(data=land$geometry,fill="grey")+
  coord_sf(datum=st_crs("+init=EPSG:32626 +units=km"))+
  geom_path(data=baseline_trajectories, 
            aes(x = x, y = y,group=ID),size = 1, 
            lineend = "round",alpha=0.15) +     
  geom_point(data=baseline_trajectories,
             aes(x = x, y = y,group=ID,shape=ID),size =4 ) + facet_wrap(~data_type) 
  labs(title = "Narwhal Trajectories before Exposure", 
       subtitle = "Time : {frame_along} h", 
       x = "X Position", 
       y = "Y Position") +
  theme_minimal()


anim <- plot_baseline_trajectories + 
  transition_reveal(along = time) + 
  labs(subtitle = "Time: {round(frame_along,1)} hours") 

# Save the animation
animate(anim, nframes = 100, fps = 5, width = 800, height = 600, 
        renderer = gifski_renderer("baseline_trajectories.gif"))


```




## Check estimation on simulations from fitted model

```{r}

signed_angle <- function(u, v) {
  #Compute signed angle in [-pi,pi] that rotates first vector into second vector 
  # as in 
  # https://math.stackexchange.com/questions/529555/signed-angle-between-2-vectors
  u <- matrix(u, ncol = 2)
  v <- matrix(v, ncol = 2)
  if (nrow(u) != nrow(v)) stop("u and v must have the same number of 
                                  rows")
  result <- as.numeric(atan2(v[,2], v[,1]) - atan2(u[,2], u[,1]))
  ind1 <- which(result > pi)
  ind2 <- which(result <= -pi)
  result[ind1] <- result[ind1] - 2*pi
  result[ind2] <- result[ind2] + 2*pi
  return(result) 
} 


add_covs_parallel <- function(data, n_cores = parallel::detectCores() - 1) {
  # Setup parallel backend
  cl <- makeCluster(n_cores)
  registerDoParallel(cl)
  
  # Split data by ID
  ids <- unique(data$ID)
  
  # Process each ID in parallel
  results <- foreach(id = ids, .combine = rbind, .packages = c("sf"),
                     .export = c("nearest_boundary_points", "is_in_land", "signed_angle","border",
                                 "D_low","D_up")  ) %dopar% {
                                   # Filter data for the current ID
                                   sub_data <- data[data$ID == id, ]
                                   n_sub <- nrow(sub_data)
                                   
                                   # Time steps
                                   dtimes <- sub_data[2:n_sub, "time"] - sub_data[1:(n_sub - 1), "time"]
                                   
                                   # Step lengths
                                   dx <- sub_data[2:n_sub, "x"] - sub_data[1:(n_sub - 1), "x"]
                                   dy <- sub_data[2:n_sub, "y"] - sub_data[1:(n_sub - 1), "y"]
                                   
                                   # Empirical velocity
                                   vexp_df <- cbind(dx / dtimes, dy / dtimes)
                                   
                                   # Nearest points on shore
                                   sub_data <-cbind(sub_data,
                                                    nearest_boundary_points(as.matrix(sub_data[, c("x", "y")]), border))
                                   
                                   # Normal vectors
                                   normal <- as.matrix(sub_data[2:n_sub, c("x", "y")] - sub_data[2:n_sub, c("p1", "p2")])
                                   
                                   # Angle between velocity and normal vector
                                   theta_coast <- signed_angle(normal, vexp_df)
                                   theta_coast <- c(theta_coast, 1)  # Adjust length
                                   
                                   # Initialize DistanceShore
                                   Dshore <- rep(0, n_sub)
                                   
                                   for (i in 1:n_sub) {
                                     y1 <- sub_data[i, "x"]
                                     y2 <- sub_data[i, "y"]
                                     if (!is_in_land(st_point(c(y1, y2)), border)) {
                                       p1 <- sub_data[i, "p1"]
                                       p2 <- sub_data[i, "p2"]
                                       Dshore[i] <- sqrt((y1 - p1)^2 + (y2 - p2)^2)
                                     }
                                   }
                                   
                                   # Calculate Ishore
                                   Ishore <- ifelse(Dshore < D_low, 1 / D_low, ifelse(Dshore > D_up, 0, 1 / Dshore))
                                   
                                   # Add columns to sub_data
                                   sub_data$theta <- theta_coast
                                   sub_data$DistanceShore <- Dshore
                                   sub_data$Ishore <- Ishore
                                   
                                   return(sub_data)
                                 }
  
  # Stop the cluster
  stopCluster(cl)
  
  return(results)
}
border=shrunk_land

# add noise
baseline_crcvm2_trajectory_lf_obs=baseline_crcvm2_trajectory_sub[,c("time","x","y","ID")]
noise=rmvn(length(baseline_crcvm2_trajectory_lf_obs$time),rep(0,2),diag(rep(0.05^2,2)))

baseline_crcvm2_trajectory_lf_obs[,c("x","y")]=baseline_crcvm2_trajectory_lf_obs[,c("x","y")]+noise
 
baseline_crcvm2_trajectory_hf_obs=baseline_crcvm2_trajectory[seq(1,nrow(baseline_crcvm2_trajectory),by=30),c("time","x","y","ID")]
noise=rmvn(length(baseline_crcvm2_trajectory_hf_obs$time),rep(0,2),diag(rep(0.05^2,2)))
baseline_crcvm2_trajectory_hf_obs[,c("x","y")]=baseline_crcvm2_trajectory_hf_obs[,c("x","y")]+noise
 

baseline_crcvm2_trajectory_lf_obs=add_covs_parallel(baseline_crcvm2_trajectory_lf_obs)
baseline_crcvm2_trajectory_hf_obs=add_covs_parallel(baseline_crcvm2_trajectory_hf_obs)

```


```{r}


plot_baseline_crcvm2_trajectory_obs=ggplot() +
  geom_sf(data=shrunk_land$geometry,fill="grey")+
  coord_sf(datum=st_crs("+init=EPSG:32626 +units=km"))+
  geom_path(data=baseline_crcvm2_trajectory_lf_obs, 
            aes(x = x, y = y,color=ID),size = 0.2, 
            lineend = "round",alpha=0.5) +     
  geom_point(data=baseline_crcvm2_trajectory_lf_obs,
             aes(x = x, y = y,color=ID),size =0.2 ) +
  theme_minimal()+ scale_color_viridis_d(labels=c("A1","A2","A3","A4","A5","A6"))+theme(
    axis.title = element_text(size = 18),
    axis.text = element_text(size = 14),
    legend.text = element_text(size = 18),
    axis.title.y = element_text(angle = 0)  # Rotate the y-axis label and adjust horizontal justification
  )


plot_dataBE12=ggplot() +
  geom_sf(data=shrunk_land$geometry,fill="grey")+
  coord_sf(datum=st_crs("+init=EPSG:32626 +units=km"))+
  geom_path(data=dataBE12, 
            aes(x = x, y = y,color=ID),size = 0.2, 
            lineend = "round",alpha=0.5) +     
  geom_point(data=dataBE12,
             aes(x = x, y = y,color=ID),size =0.2 ) +
  theme_minimal()+ scale_color_viridis_d(labels=c("A1","A2","A3","A4","A5","A6"))+theme(
    axis.title = element_text(size = 18),
    axis.text = element_text(size = 14),
    legend.text = element_text(size = 18),
    axis.title.y = element_text(angle = 0)  # Rotate the y-axis label and adjust horizontal justification
  )

final_plot=ggarrange(plotlist=list(plot_dataBE12,plot_baseline_crcvm2_trajectory_obs),
                     ncol=2, nrow=1, common.legend = TRUE, legend="bottom",
                     labels= c("Observed","Simulated"))


ggsave("plot_baseline_crcvm2_trajectory.pdf", plot = final_plot,path="baseline_racvm2",width = 14, height = 8)
```



```{r}



# Determine the common x-axis limits
x_min <- min(baseline_crcvm2_trajectory_hf_obs$DistanceShore, 
              dataBE12$DistanceShore_translated, na.rm = TRUE)
x_max <- max(baseline_crcvm2_trajectory_hf_obs$DistanceShore, 
              dataBE12$DistanceShore_translated, na.rm = TRUE)

# Plot the two histograms with consistent x-axis scales
Dshore_hist_crcvm2 <- ggplot(baseline_crcvm2_trajectory_hf_obs) +
  geom_histogram(aes(x = DistanceShore), color = "red", fill = "white", bins = 30) +
  theme_minimal() +
  xlim(x_min, x_max) +
  xlab("Distance to Shore") +
  ggtitle("Simulated data") +theme(
    axis.title = element_text(size = 18),
    axis.text = element_text(size = 14),
    legend.text = element_text(size = 18),
    axis.title.y = element_text(angle = 0)  # Rotate the y-axis label and adjust horizontal justification
  )



Dshore_hist_dataBE12 <- ggplot(dataBE12) +
  geom_histogram(aes(x = DistanceShore_translated), color = "red", fill = "white", bins = 30) +
  theme_minimal() +
  xlim(x_min, x_max) +
  xlab("Distance to Shore ") +
  ggtitle("Observed data")+theme(
    axis.title = element_text(size = 18),
    axis.text = element_text(size = 14),
    legend.text = element_text(size = 18),
    axis.title.y = element_text(angle = 0)  # Rotate the y-axis label and adjust horizontal justification
  )


# Combine the plots
Dshore_histograms <- Dshore_hist_crcvm2 + Dshore_hist_dataBE12

Dshore_histograms

# Save the plot as a PDF
ggsave("Dshore_histograms.pdf", plot = Dshore_histograms,path="baseline_racvm2", width = 10, height = 5)

```

```{r}

#initial parameters
par0 <- c(0,0,1,1,0)
init_lambda=c(1/0.5^2,1/0.5^2,m1$sp)

#mapping for fixed smoothing penalties
new_map=list("log_lambda"=factor(c(1,2,rep(NA,2))))

#Fixed measurement error
sigma_obs=0.05
H=array(rep(sigma_obs^2*diag(2),length(baseline_crcvm2_trajectory_hf_obs$time)),
        dim=c(2,2,length(baseline_crcvm2_trajectory_hf_obs$time)))


#parameters formulas
formulas <- list(mu1 = ~1 ,mu2 =~1,tau =~s(ID,bs="re"),nu=~s(ID,bs="re"),
                   omega=~te(theta,Ishore,k=c(5,5),bs=c("cs")))

# Fit baseline
baseline_racvm2_check<- SDE$new(formulas = formulas,
                                data = baseline_crcvm2_trajectory_hf_obs[baseline_crcvm2_trajectory_hf_obs$ID %in% c("Asgeir","Frederik","Kyrri","Nemo"),],type = "RACVM_SSM",
                    response = c("x","y"),par0 = par0,other_data=list("H"=H),
                    fixpar=c("mu1","mu2"))

baseline_racvm2_check$update_lambda(init_lambda)
baseline_racvm2_check$update_map(new_map)
baseline_racvm2_check$fit()

```

```{r}
make_final_baseline_tab(baseline_racvm2_check,include_sigma_obs=FALSE)
```

```{r}

xmin=list("Ishore"=1/3)
xmax=list("Ishore"=1/0.3)
link=list("Ishore"=\(x) 1/x)
xlabel=list("Ishore"="Distance to shore")

baseline_racvm2_check$get_all_plots(baseline=NULL,
      xmin=xmin,xmax=xmax,link=link,xlabel=xlabel,show_CI="pointwise")
```

We continue the analysis with the fitted baseline model \texttt{baseline\_racvm2}.


# Fit response models


## Try a model directly on the whole data

```{r fit response all data}

par0 <- c(0,0,1,4,0)

sigma_obs=0.05
H=array(rep(sigma_obs^2*diag(2),length(all_data$time)),dim=c(2,2,length(all_data$time)))

#model formula
formulas <- list(mu1=~1,mu2=~1,tau =~ExpShip+s(ID,bs="re"),
                 nu=~ExpShip+s(ID,bs="re"),
                 omega=~te(theta_translated,Ishore_translated,k=5,bs="cs"))

response0<- SDE$new(formulas = formulas,data = all_data,type = "RACVM_SSM",response = c("x","y"),
                    par0 = par0,other_data=list("H"=H),fixpar=c("mu1","mu2"))

response0$update_map(list("log_lambda"=factor(c(1,2,NA,NA))))
response0$update_lambda(exp(c(3,3,m1$sp)))

response0$fit()
```


```{r plot estimates response all data}
#plot parameters
xmin=list("AngleNormal"=-pi,"ExpShip"=1/45,"Ishore"=1/3)
xmax=list("AngleNormal"=pi,"ExpShip"=1/3,"Ishore"=1/0.1)
link=list("ExpShip"=(\(x) 1/x),"Ishore"=(\(x) 1/x))
xlabel=list("ExpShip"="Distance to ship","Ishore"="Distance to shore")
response0$get_all_plots(baseline=NULL,
      xmin=xmin, xmax=xmax,link=link,xlabel=xlabel,show_CI="pointwise")
```

## Response model with splines of ExpShip

```{r fit response splines}


par0 <- c(0,0,1,4,0)

sigma_obs=0.05
H=array(rep(sigma_obs^2*diag(2),length(dataAE$time)),dim=c(2,2,length(dataAE$time)))


#model formula
formulas <- list(mu1=~1,mu2=~1,
                 tau =~s(ExpShip,k=3,bs="cs")+s(ID,bs="re"),
                 nu=~s(ExpShip,k=3,bs="cs")+s(ID,bs="re"),
                 omega=~te(theta_translated,Ishore_translated,k=c(5,5),bs="cs"))

#mapping for fixed coefficients
new_map=list(coeff_re=factor(c(1,2,rep(NA,N),
                    3,4,rep(NA,N),rep(NA,24))),coeff_fe=factor(rep(NA,5)),
                    log_lambda=factor(c(5,NA,6,NA,rep(NA,2))))
#Fit baseline
response_racvm_sp<- SDE$new(formulas = formulas,data = dataAE,type = "RACVM_SSM",response = c("x","y"),
                    par0 = par0,other_data=list("H"=H),fixpar=c("mu1","mu2"))

new_coeff_re=c(rep(0,2),baseline_racvm2$coeff_re()[paste("tau.s(ID).",1:N,sep=""),1],rep(0,2),
               baseline_racvm2$coeff_re()[paste("nu.s(ID).",1:N,sep=""),1],
               baseline_racvm2$coeff_re()[paste("omega.te(theta_translated,Ishore_translated).",1:24,sep=""),1])
new_lambda=c(1,baseline_racvm2$lambda()["tau.s(ID)",1],1,baseline_racvm2$lambda()["nu.s(ID)",1],
             baseline_racvm2$lambda()[3:4,1])

response_racvm_sp$update_map(new_map)
response_racvm_sp$update_coeff_re(new_coeff_re)
response_racvm_sp$update_coeff_fe(baseline_racvm2$coeff_fe()[,1])

response_racvm_sp$update_lambda(new_lambda)

response_racvm_sp$fit()


```

```{r get results response splines}
#plot parameters
xmin=list("Ishore_translated"=1/3,"ExpShip"=1/60)
xmax=list("Ishore_translated"=1/0.5,"ExpShip"=1/5)
link=list("Ishore_translated"=(\(x) 1/x),"ExpShip"=(\(x) 1/x))
xlabel=list("Ishore_translated"="Distance to shore","ExpShip"="Distance to ship")

plots_res_racvm_sp=response_racvm_sp$get_all_plots(baseline=baseline_racvm2,xmin=xmin,
                                         xmax=xmax,link=link,xlabel=xlabel,show_CI="simultaneous")

plots_res_racvm_sp
```



## Log linear RACVM response model with exponential of ExpShip

```{r fit response log linear}

par0=c(0,0,1,4,0)

#define model
formulas <- list(mu1=~1,mu2=~1,tau =~ExpShip+s(ID,bs="re"),
                 nu=~ExpShip+s(ID,bs="re"),
                 omega=~te(theta_translated,Ishore_translated,k=c(5,5),bs="cs"))

new_map=list(coeff_re=factor(c(rep(NA,12),rep(NA,24))),coeff_fe=factor(c(NA,NA,NA,1,NA,2,NA)),
                             log_lambda=factor(c(NA,NA,NA,NA)))

#sigma_obs=exp(as.list(baseline_racvm2$tmb_rep(),what="Estimate")$log_sigma_obs)
sigma_obs=0.05
H=array(rep(sigma_obs^2*diag(2),n_post),dim=c(2,2,n_post))
# Fit response
response_racvm_exp<- SDE$new(formulas = formulas,data = dataAE,type = "RACVM_SSM",
                    response = c("x","y"),par0 = par0,fixpar=c("mu1","mu2"),
                    other_data=list("H"=H))


new_coeff_fe=c(baseline_racvm2$coeff_fe()[1:3,1],0,baseline_racvm2$coeff_fe()[4,1],0,
               baseline_racvm2$coeff_fe()[5,1])
new_coeff_re=c(baseline_racvm2$coeff_re()[paste("tau.s(ID).",1:N,sep=""),1],
               baseline_racvm2$coeff_re()[paste("nu.s(ID).",1:N,sep=""),1],
               baseline_racvm2$coeff_re()[paste("omega.te(theta_translated,Ishore_translated).",1:24,sep=""),1])
new_lambda=c(baseline_racvm2$lambda()["tau.s(ID)",1],
             baseline_racvm2$lambda()["nu.s(ID)",1],baseline_racvm2$lambda()[3:4,1])

response_racvm_exp$update_map(new_map)
response_racvm_exp$update_coeff_re(new_coeff_re)
response_racvm_exp$update_coeff_fe(new_coeff_fe)

response_racvm_exp$update_lambda(new_lambda)

response_racvm_exp$fit()

```

```{r plot estimates response log linear}

#plot parameters
xmin=list("Ishore_translated"=1/3,"ExpShip"=1/60)
xmax=list("Ishore_translated"=1/0.5,"ExpShip"=1/5)
link=list("Ishore_translated"=(\(x) 1/x),"ExpShip"=(\(x) 1/x))
xlabel=list("Ishore_translated"="Distance to shore","ExpShip"="Distance to ship")


plots_res_racvm_exp=response_racvm_exp$get_all_plots(baseline=baseline_racvm2,xmin=xmin,
                            xmax=xmax,link=link,xlabel=xlabel,show_CI="pointwise")


```

```{r display plots response log linear}

#print plots
plots_res_racvm_exp

```

```{r save plots response_racvm_exp,results="hide",cache=TRUE,message=FALSE}
# Create directory
if (!dir.exists("response_racvm_exp")) {
    dir.create("response_racvm_exp", recursive = TRUE)
}

# Use lapply to save each plot
lapply(seq_along(plots_res_racvm_exp), function(i) {
    
    plot<-plots_res_racvm_exp[[i]]
    plot_name <- names(plots_res_racvm_exp)[i]
    file_path <- file.path("response_racvm_exp", plot_name)
    
    # Check if the plot is a ggplot or plotly object
    if (inherits(plot, "ggplot")) {
      ggsave(file_path, plot, device = "pdf")
    } else if (inherits(plot, "plotly")) {
      saveWidget(plot, file_path)
  }
    })
```

```{r get final estimates response_racvm_exp}

make_final_response_tab<-function(sde,show=TRUE) {
  
  
  post_coeff=sde$post_coeff(n_post=10000)
  post_par=list(
  "alpha_tau"=post_coeff$coeff_fe[,"tau.ExpShip"],
  "alpha_nu"=post_coeff$coeff_fe[,"nu.ExpShip"])

  mean_par=lapply(post_par,mean)
  sd_par=lapply(post_par,sd)
  quant_par <- lapply(post_par,
                      quantile, probs = c(0.025, 0.975))
  
  parameter_names <- names(mean_par)
  estimates <- mean_par
  conf_intervals <- sapply(parameter_names, function(param) {
    sprintf("$[%.2f; %.2f]$", quant_par[[param]][1], 
            quant_par[[param]][2])
  })
  
  table_data <- data.frame(
    Parameter = 
      c("$\\alpha_{\\tau}$","$\\alpha_{\\nu}$"),
    Estimate = sprintf("$%.2f$", mean_par),
    CI = conf_intervals,
    stringsAsFactors = FALSE
  )
  xtab <- xtable(
    table_data,
    caption = "Response log linear estimations",
    label = "table:response_log_linear_estimations"
  )
  
  print(
    xtab,type="latex",
    include.rownames = FALSE,
    sanitize.text.function = identity,  # Prevent escaping of LaTeX math symbols
    hline.after = c(-1, 0, nrow(table_data)),
    table.placement="H")

  }

make_final_response_tab(response_racvm_exp)
```



These confidence intervals do not include the uncertainty from the baseline estimations.

## Thorough uncertainty quantification 

```{r, message=FALSE,results="hide"}

post_coeff_bas_racvm2=baseline_racvm2$post_coeff(n_post=1000)
#posterior samples of the coefficient of the baseline model
post_coeff_re=post_coeff_bas_racvm2$coeff_re[1:100,]
post_coeff_fe=post_coeff_bas_racvm2$coeff_fe[1:100,]
post_coeff_lambda=exp(post_coeff_bas_racvm2$log_lambda[1:100,])




par0=c(0,0,1,4,0)

#define model
formulas <- list(mu1=~1,mu2=~1,tau =~ExpShip+s(ID,bs="re"),
                 nu=~ExpShip+s(ID,bs="re"),
                 omega=~te(theta_translated,Ishore_translated,k=c(5,5),bs="cs"))

  
new_map=list(coeff_re=factor(c(rep(NA,12),rep(NA,24))),coeff_fe=factor(c(NA,NA,NA,1,NA,2,NA)),
                             log_lambda=factor(c(NA,NA,NA,NA)))

sigma_obs=0.05
H=array(rep(sigma_obs^2*diag(2),n_post),dim=c(2,2,n_post))

alpha_estimates=matrix(rep(0,2*nrow(post_coeff_fe)),ncol=2)
alpha_std=matrix(rep(0,2*nrow(post_coeff_fe)),ncol=2)

models_list=list()

for (i in 1:nrow(post_coeff_fe)) {

    response_racvm_exp_temp<- SDE$new(formulas = formulas,data = dataAE,type = "RACVM_SSM",
                        response = c("x","y"),par0 = par0,fixpar=c("mu1","mu2"),
                        other_data=list("H"=H))
    
    new_coeff_fe=c(post_coeff_fe[i,1:3],0,post_coeff_fe[i,4],0,post_coeff_fe[i,5])
    
    
    new_coeff_re=post_coeff_re[i,]
    new_lambda=post_coeff_lambda[i,]
    
    response_racvm_exp_temp$update_map(new_map)
    response_racvm_exp_temp$update_coeff_re(new_coeff_re)
    response_racvm_exp_temp$update_coeff_fe(new_coeff_fe)
    
    response_racvm_exp_temp$update_lambda(new_lambda)
    
    response_racvm_exp_temp$fit()
    
    
    est_alpha=as.list(response_racvm_exp_temp$tmb_rep(),what="Est")$coeff_fe[c("tau.ExpShip","nu.ExpShip"),1]
    std_alpha=as.list(response_racvm_exp_temp$tmb_rep(),what="Std")$coeff_fe[c("tau.ExpShip","nu.ExpShip"),1]
    
    alpha_estimates[i,]=est_alpha
    alpha_std[i,]=std_alpha
    
    models_list[[i]]=response_racvm_exp_temp
}

colnames(alpha_estimates)=c("tau.ExpShip","nu.ExpShip")
colnames(alpha_std)=c("tau.ExpShip","nu.ExpShip")

```



```{r propagate uncertainty coefficient log -linear model}

mean_alpha=list(alpha_tau=mean(alpha_estimates[,1]),
                alpha_nu=mean(alpha_estimates[,2]))
quant_alpha<- list(
  alpha_tau=quantile(alpha_estimates[,1],probs = c(0.025, 0.975)),
  alpha_nu=quantile(alpha_estimates[,2],probs = c(0.025, 0.975)))

```

```{r propagated CI alpha log linear coefficients, message=FALSE}

parameter_names <- names(mean_alpha)
estimates <- mean_alpha
conf_intervals <- sapply(parameter_names, function(param) {
  sprintf("$[%.2f; %.2f]$", quant_alpha[[param]][1], 
          quant_alpha[[param]][2])
})


table_data <- data.frame(
  Parameter = 
    c("$\\alpha_{\\tau}$","$\\alpha_{\\nu}$"),
  Estimate = sprintf("$%.2f$", mean_alpha),
  CI = conf_intervals,
  stringsAsFactors = FALSE
)

```


```{r,results='asis',echo=FALSE}
xtab <- xtable(
  table_data,
  caption = "Response log linear estimations with propagated uncertainty",
  label = "table:response_log_linear_estimations_with_propagated_uncertainty"
)

print(
  xtab,type="latex",
  include.rownames = FALSE,
  sanitize.text.function = identity,  
  hline.after = c(-1, 0, nrow(table_data)),
  table.placement="H"
  
)
```





```{r all CI plots,cache=TRUE}

CI_plots=lapply(models_list,function(model) { 
  model$get_all_plots(baseline=NULL,xmin=xmin,xmax=xmax,
                      link=link,xlabel=xlabel,show_CI="pointwise")})


```

```{r plot smooth parameters with propagated uncertainty,results='hide'}

# Extract data for each estimated smooth parameter
tau_CI_data <- lapply(CI_plots, function(plot) {
  ggplot_build(plot$fe_tau_ExpShip)$data[[1]][,c("x","y")]
})
nu_CI_data <- lapply(CI_plots, function(plot) {
  ggplot_build(plot$fe_nu_ExpShip)$data[[1]][,c("x","y")]
})

# Get confidence intervals as quantiles of estimated parameters

# Combine the x columns from all data frames into a matrix
x_matrix_tau <- do.call(cbind, lapply(tau_CI_data, function(df) df$y))
x_matrix_nu <- do.call(cbind, lapply(nu_CI_data, function(df) df$y))
# Compute the 5% and 95% quantiles row-wise
quantiles_tau <- apply(x_matrix_tau, 1, 
                       function(row) quantile(row, probs = c(0.025, 0.975)))
quantiles_nu <- apply(x_matrix_nu, 1,
                      function(row) quantile(row, probs = c(0.025, 0.975)))

# Transpose and format the results into a data frame
quantiles_tau <- as.data.frame(t(quantiles_tau))
colnames(quantiles_tau) <- c("low", "up")
quantiles_nu <- as.data.frame(t(quantiles_nu))
colnames(quantiles_nu) <- c("low", "up")

# Add the "true" estimated smooth
plots=response_racvm_exp$get_all_plots(
  baseline=baseline_racvm2,xmin=xmin,xmax=xmax,
  link=link,xlabel=xlabel,show_CI="pointwise")
est_tau=ggplot_build(plots$fe_tau_ExpShip)$data[[1]][,c("x","y")]
est_nu=ggplot_build(plots$fe_nu_ExpShip)$data[[1]][,c("x","y")]
est_tau=cbind(est_tau,quantiles_tau)
est_nu=cbind(est_nu,quantiles_nu) 

est_tau$baseline=ggplot_build(plots$fe_tau_ExpShip)$data[[2]][,"y"]
est_nu$baseline=ggplot_build(plots$fe_nu_ExpShip)$data[[2]][,"y"]


plot_tau_response_exp <- ggplot(data = est_tau) +
  geom_line(aes(x = x, y = y), color = "steelblue", size = 1) +
  geom_line(aes(x=x,y=baseline),color="steelblue",size=1,linetype="dashed")+
  geom_ribbon(aes(x = x, ymin = low, ymax = up), 
              fill = "lightblue", alpha = 0.3) +
  labs(
    x = "Distance to Ship",
    y = expression(tau)) +
  theme_minimal() +theme(
    axis.title.x = element_text(size=22),
    axis.title.y = element_text(size=22, angle=0, vjust=0.5, margin = margin(r = 10)),
    axis.text.x = element_text(size=18),
    axis.text.y = element_text(size=18),
    legend.title = element_text(size=18),
    legend.text = element_text(size=18)
  )

# Enhanced plot for nu
plot_nu_response_exp <- ggplot(data = est_nu) +
  geom_line(aes(x = x, y = y), color = "darkorange", size = 1) +
   geom_line(aes(x,baseline),color="darkorange",size=1,linetype="dashed")+
  geom_ribbon(aes(x = x, ymin = low, ymax = up), 
              fill = "navajowhite", alpha = 0.3) +
  labs(
    x = "Distance to Ship",
    y = expression(nu)) +
  theme_minimal() +theme(
    axis.title.x = element_text(size=22),
    axis.title.y = element_text(size=22, angle=0, vjust=0.5, margin = margin(r = 10)),
    axis.text.x = element_text(size=18),
    axis.text.y = element_text(size=18),
    legend.title = element_text(size=18),
    legend.text = element_text(size=18)
  )


```

```{r}

ggsave("fe_tau_ExpShip_final.pdf", plot=plot_tau_response_exp,
       path="response_racvm_exp", width=10, height=6, units="in")

ggsave("fe_nu_ExpShip_final.pdf", plot=plot_nu_response_exp,
       path="response_racvm_exp", width=10, height=6, units="in")
plot_tau_response_exp
plot_nu_response_exp

```

## Compute recovery distances

```{r}
make_recovery_distances_tab<-function(p) {
  
  parameter_names=names(mean_alpha)
  scaling=as.list(c(log(1-p),log(1+p)))
  names(scaling)=parameter_names
  estimates <- sapply(parameter_names,function(param) {
    mean_alpha[[param]]/scaling[[param]]})
  
  conf_intervals <- sapply(parameter_names, function(param) {
    sprintf("$[%.2f; %.2f]$", quant_alpha[[param]][1]/scaling[[param]], 
            quant_alpha[[param]][2]/scaling[[param]])
  })
  
  
  table_data <- data.frame(
    Parameter = 
      c("$D_{\\tau}^{ship}$","$D_{\\nu}^{ship}$"),
    Estimate = sprintf("$%.2f$", estimates),
    CI = conf_intervals,
    stringsAsFactors = FALSE
  )
  
  xtab <- xtable(
  table_data,
  caption = "Estimated recovery distances of the baseline values",
  label = paste0("table:recovery_distances_",p)
  )

  print(
    xtab,type="latex",
    include.rownames = FALSE,
    sanitize.text.function = identity,  
    hline.after = c(-1, 0, nrow(table_data)),
    table.placement="H"
  
  )
}

make_recovery_distances_tab(0.5)

make_recovery_distances_tab(0.1)
```


The main difference with the CVM without omega, that is without influence of the shore, is that we now get much wider confidence intervals for the recovery distances. However, the mean values are somehow similar.
